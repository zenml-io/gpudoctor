{
  "$schema": "./schema.json",
  "version": "0.1.0",
  "last_updated": "2025-12-08",
  "images": [
    {
      "id": "ngc-jax-23-10",
      "name": "nvcr.io/nvidia/jax:23.10-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.10",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "jax",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "llm",
          "scientific-computing",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 6351,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/jax",
        "documentation": "https://docs.nvidia.com/deeplearning/frameworks/jax-release-notes/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ngc-jax-24-04",
      "name": "nvcr.io/nvidia/jax:24.04-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.10",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "jax",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "llm",
          "scientific-computing",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 5388,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/jax",
        "documentation": "https://docs.nvidia.com/deeplearning/frameworks/jax-release-notes/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ngc-jax-24-10",
      "name": "nvcr.io/nvidia/jax:24.10-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.10",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "jax",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "llm",
          "scientific-computing",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 6647,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/jax",
        "documentation": "https://docs.nvidia.com/deeplearning/frameworks/jax-release-notes/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ngc-jax-25-01",
      "name": "nvcr.io/nvidia/jax:25.01-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.10",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "jax",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "llm",
          "scientific-computing",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 8589,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/jax",
        "documentation": "https://docs.nvidia.com/deeplearning/frameworks/jax-release-notes/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ngc-nemo-23-10",
      "name": "nvcr.io/nvidia/nemo:23.10",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.10",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "nemo",
          "version": "varies-by-release"
        },
        {
          "name": "pytorch",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "llm",
          "nlp",
          "audio",
          "multimodal"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 11284,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/nemo",
        "documentation": "https://docs.nvidia.com/nemo-framework/user-guide/latest/",
        "source": "https://github.com/NVIDIA/NeMo"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ngc-nemo-24-03",
      "name": "nvcr.io/nvidia/nemo:24.03",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.10",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "nemo",
          "version": "varies-by-release"
        },
        {
          "name": "pytorch",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "llm",
          "nlp",
          "audio",
          "multimodal"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 17501,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/nemo",
        "documentation": "https://docs.nvidia.com/nemo-framework/user-guide/latest/",
        "source": "https://github.com/NVIDIA/NeMo"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ngc-nemo-24-05",
      "name": "nvcr.io/nvidia/nemo:24.05",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.10",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "nemo",
          "version": "varies-by-release"
        },
        {
          "name": "pytorch",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "llm",
          "nlp",
          "audio",
          "multimodal"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 24883,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/nemo",
        "documentation": "https://docs.nvidia.com/nemo-framework/user-guide/latest/",
        "source": "https://github.com/NVIDIA/NeMo"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ngc-nemo-24-07",
      "name": "nvcr.io/nvidia/nemo:24.07",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.10",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "nemo",
          "version": "varies-by-release"
        },
        {
          "name": "pytorch",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "llm",
          "nlp",
          "audio",
          "multimodal"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 28986,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/nemo",
        "documentation": "https://docs.nvidia.com/nemo-framework/user-guide/latest/",
        "source": "https://github.com/NVIDIA/NeMo"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ngc-nemo-24-09",
      "name": "nvcr.io/nvidia/nemo:24.09",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.10",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "nemo",
          "version": "varies-by-release"
        },
        {
          "name": "pytorch",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "llm",
          "nlp",
          "audio",
          "multimodal"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 32182,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/nemo",
        "documentation": "https://docs.nvidia.com/nemo-framework/user-guide/latest/",
        "source": "https://github.com/NVIDIA/NeMo"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ngc-nemo-24-12",
      "name": "nvcr.io/nvidia/nemo:24.12",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.10",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "nemo",
          "version": "varies-by-release"
        },
        {
          "name": "pytorch",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "llm",
          "nlp",
          "audio",
          "multimodal"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 29119,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/nemo",
        "documentation": "https://docs.nvidia.com/nemo-framework/user-guide/latest/",
        "source": "https://github.com/NVIDIA/NeMo"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ngc-pytorch-23-10",
      "name": "nvcr.io/nvidia/pytorch:23.10-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.12",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "multimodal",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 10107,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch",
        "documentation": "https://docs.nvidia.com/deeplearning/frameworks/pytorch-release-notes/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ngc-pytorch-23-11",
      "name": "nvcr.io/nvidia/pytorch:23.11-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.12",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "multimodal",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 10041,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch",
        "documentation": "https://docs.nvidia.com/deeplearning/frameworks/pytorch-release-notes/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ngc-pytorch-23-12",
      "name": "nvcr.io/nvidia/pytorch:23.12-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.12",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "multimodal",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 10128,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch",
        "documentation": "https://docs.nvidia.com/deeplearning/frameworks/pytorch-release-notes/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ngc-pytorch-24-01",
      "name": "nvcr.io/nvidia/pytorch:24.01-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.12",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "multimodal",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 10196,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch",
        "documentation": "https://docs.nvidia.com/deeplearning/frameworks/pytorch-release-notes/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ngc-pytorch-24-02",
      "name": "nvcr.io/nvidia/pytorch:24.02-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.12",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "multimodal",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 10256,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch",
        "documentation": "https://docs.nvidia.com/deeplearning/frameworks/pytorch-release-notes/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ngc-pytorch-24-03",
      "name": "nvcr.io/nvidia/pytorch:24.03-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.12",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "multimodal",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 8797,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch",
        "documentation": "https://docs.nvidia.com/deeplearning/frameworks/pytorch-release-notes/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ngc-pytorch-24-04",
      "name": "nvcr.io/nvidia/pytorch:24.04-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.12",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "multimodal",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 8890,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch",
        "documentation": "https://docs.nvidia.com/deeplearning/frameworks/pytorch-release-notes/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ngc-pytorch-24-05",
      "name": "nvcr.io/nvidia/pytorch:24.05-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.12",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "multimodal",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 8778,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch",
        "documentation": "https://docs.nvidia.com/deeplearning/frameworks/pytorch-release-notes/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ngc-pytorch-24-06",
      "name": "nvcr.io/nvidia/pytorch:24.06-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.12",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "multimodal",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 8915,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch",
        "documentation": "https://docs.nvidia.com/deeplearning/frameworks/pytorch-release-notes/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ngc-pytorch-24-07",
      "name": "nvcr.io/nvidia/pytorch:24.07-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.12",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "multimodal",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 9558,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch",
        "documentation": "https://docs.nvidia.com/deeplearning/frameworks/pytorch-release-notes/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ngc-pytorch-24-08",
      "name": "nvcr.io/nvidia/pytorch:24.08-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.12",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "multimodal",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 9702,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch",
        "documentation": "https://docs.nvidia.com/deeplearning/frameworks/pytorch-release-notes/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ngc-pytorch-24-09",
      "name": "nvcr.io/nvidia/pytorch:24.09-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.12",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "multimodal",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 10178,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch",
        "documentation": "https://docs.nvidia.com/deeplearning/frameworks/pytorch-release-notes/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ngc-pytorch-24-10",
      "name": "nvcr.io/nvidia/pytorch:24.10-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.12",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "multimodal",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 10204,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch",
        "documentation": "https://docs.nvidia.com/deeplearning/frameworks/pytorch-release-notes/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ngc-pytorch-24-11",
      "name": "nvcr.io/nvidia/pytorch:24.11-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.12",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "multimodal",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 10457,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch",
        "documentation": "https://docs.nvidia.com/deeplearning/frameworks/pytorch-release-notes/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ngc-pytorch-24-12",
      "name": "nvcr.io/nvidia/pytorch:24.12-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": {
        "version": "12.6",
        "cudnn": "9.5",
        "min_driver": "560.00",
        "compute_capabilities": [
          "7.0",
          "7.5",
          "8.0",
          "8.6",
          "8.9",
          "9.0"
        ]
      },
      "runtime": {
        "python": "3.12",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "2.6.0"
        },
        {
          "name": "torchvision",
          "version": "0.21.0"
        },
        {
          "name": "torchaudio",
          "version": "2.6.0"
        },
        {
          "name": "transformer-engine",
          "version": "1.13"
        },
        {
          "name": "apex",
          "version": "latest"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "multimodal",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 10417,
        "uncompressed_mb": 25000
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch",
        "documentation": "https://docs.nvidia.com/deeplearning/frameworks/pytorch-release-notes/",
        "source": null
      },
      "recommended_for": [
        "Maximum NVIDIA GPU performance",
        "Large-scale training",
        "H100/A100 optimized workloads"
      ],
      "system_packages": [
        "git",
        "wget",
        "curl",
        "gcc",
        "g++",
        "make"
      ],
      "notes": "NVIDIA-optimized PyTorch with Transformer Engine, APEX, and NCCL. Best performance on H100, A100, and data center GPUs. Monthly releases with security patches."
    },
    {
      "id": "ngc-pytorch-25-01",
      "name": "nvcr.io/nvidia/pytorch:25.01-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.12",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "multimodal",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 12892,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch",
        "documentation": "https://docs.nvidia.com/deeplearning/frameworks/pytorch-release-notes/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ngc-rapids-23-10-cuda12-0-py3-10",
      "name": "nvcr.io/nvidia/rapidsai/base:23.10-cuda12.0-py3.10",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.0"
      },
      "runtime": {
        "python": "3.10",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "cudf",
          "version": "varies-by-release"
        },
        {
          "name": "cuml",
          "version": "varies-by-release"
        },
        {
          "name": "cugraph",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "training",
        "workloads": [
          "classical-ml",
          "scientific-computing",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 4273,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/rapidsai/containers/base",
        "documentation": "https://docs.rapids.ai/",
        "source": "https://github.com/rapidsai"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ngc-rapids-23-12-cuda12-0-py3-10",
      "name": "nvcr.io/nvidia/rapidsai/base:23.12-cuda12.0-py3.10",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.0"
      },
      "runtime": {
        "python": "3.10",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "cudf",
          "version": "varies-by-release"
        },
        {
          "name": "cuml",
          "version": "varies-by-release"
        },
        {
          "name": "cugraph",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "training",
        "workloads": [
          "classical-ml",
          "scientific-computing",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 4363,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/rapidsai/containers/base",
        "documentation": "https://docs.rapids.ai/",
        "source": "https://github.com/rapidsai"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ngc-rapids-24-02-cuda12-0-py3-10",
      "name": "nvcr.io/nvidia/rapidsai/base:24.02-cuda12.0-py3.10",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.0"
      },
      "runtime": {
        "python": "3.10",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "cudf",
          "version": "varies-by-release"
        },
        {
          "name": "cuml",
          "version": "varies-by-release"
        },
        {
          "name": "cugraph",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "training",
        "workloads": [
          "classical-ml",
          "scientific-computing",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 4132,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/rapidsai/containers/base",
        "documentation": "https://docs.rapids.ai/",
        "source": "https://github.com/rapidsai"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ngc-rapids-24-04-cuda12-2-py3-10",
      "name": "nvcr.io/nvidia/rapidsai/base:24.04-cuda12.2-py3.10",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.2"
      },
      "runtime": {
        "python": "3.10",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "cudf",
          "version": "varies-by-release"
        },
        {
          "name": "cuml",
          "version": "varies-by-release"
        },
        {
          "name": "cugraph",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "training",
        "workloads": [
          "classical-ml",
          "scientific-computing",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 4471,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/rapidsai/containers/base",
        "documentation": "https://docs.rapids.ai/",
        "source": "https://github.com/rapidsai"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ngc-rapids-24-06-cuda12-2-py3-11",
      "name": "nvcr.io/nvidia/rapidsai/base:24.06-cuda12.2-py3.11",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.2"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "cudf",
          "version": "varies-by-release"
        },
        {
          "name": "cuml",
          "version": "varies-by-release"
        },
        {
          "name": "cugraph",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "training",
        "workloads": [
          "classical-ml",
          "scientific-computing",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 4820,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/rapidsai/containers/base",
        "documentation": "https://docs.rapids.ai/",
        "source": "https://github.com/rapidsai"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ngc-rapids-24-08-cuda12-5-py3-11",
      "name": "nvcr.io/nvidia/rapidsai/base:24.08-cuda12.5-py3.11",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.5"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "cudf",
          "version": "varies-by-release"
        },
        {
          "name": "cuml",
          "version": "varies-by-release"
        },
        {
          "name": "cugraph",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "training",
        "workloads": [
          "classical-ml",
          "scientific-computing",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 5317,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/rapidsai/containers/base",
        "documentation": "https://docs.rapids.ai/",
        "source": "https://github.com/rapidsai"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ngc-rapids-24-10-cuda12-5-py3-12",
      "name": "nvcr.io/nvidia/rapidsai/base:24.10-cuda12.5-py3.12",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.5"
      },
      "runtime": {
        "python": "3.12",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "cudf",
          "version": "varies-by-release"
        },
        {
          "name": "cuml",
          "version": "varies-by-release"
        },
        {
          "name": "cugraph",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "training",
        "workloads": [
          "classical-ml",
          "scientific-computing",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 5964,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/rapidsai/containers/base",
        "documentation": "https://docs.rapids.ai/",
        "source": "https://github.com/rapidsai"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ngc-tensorflow-23-10",
      "name": "nvcr.io/nvidia/tensorflow:23.10-tf2-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.10",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "tensorflow",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "classical-ml",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 7057,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tensorflow",
        "documentation": "https://docs.nvidia.com/deeplearning/frameworks/tensorflow-release-notes/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ngc-tensorflow-23-11",
      "name": "nvcr.io/nvidia/tensorflow:23.11-tf2-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.10",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "tensorflow",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "classical-ml",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 6957,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tensorflow",
        "documentation": "https://docs.nvidia.com/deeplearning/frameworks/tensorflow-release-notes/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ngc-tensorflow-23-12",
      "name": "nvcr.io/nvidia/tensorflow:23.12-tf2-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.10",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "tensorflow",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "classical-ml",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 6993,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tensorflow",
        "documentation": "https://docs.nvidia.com/deeplearning/frameworks/tensorflow-release-notes/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ngc-tensorflow-24-01",
      "name": "nvcr.io/nvidia/tensorflow:24.01-tf2-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.10",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "tensorflow",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "classical-ml",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 7050,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tensorflow",
        "documentation": "https://docs.nvidia.com/deeplearning/frameworks/tensorflow-release-notes/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ngc-tensorflow-24-02",
      "name": "nvcr.io/nvidia/tensorflow:24.02-tf2-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.10",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "tensorflow",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "classical-ml",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 7046,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tensorflow",
        "documentation": "https://docs.nvidia.com/deeplearning/frameworks/tensorflow-release-notes/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ngc-tensorflow-24-03",
      "name": "nvcr.io/nvidia/tensorflow:24.03-tf2-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.10",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "tensorflow",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "classical-ml",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 6728,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tensorflow",
        "documentation": "https://docs.nvidia.com/deeplearning/frameworks/tensorflow-release-notes/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ngc-tensorflow-24-04",
      "name": "nvcr.io/nvidia/tensorflow:24.04-tf2-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.10",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "tensorflow",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "classical-ml",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 6733,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tensorflow",
        "documentation": "https://docs.nvidia.com/deeplearning/frameworks/tensorflow-release-notes/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ngc-tensorflow-24-05",
      "name": "nvcr.io/nvidia/tensorflow:24.05-tf2-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.10",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "tensorflow",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "classical-ml",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 6699,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tensorflow",
        "documentation": "https://docs.nvidia.com/deeplearning/frameworks/tensorflow-release-notes/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ngc-tensorflow-24-06",
      "name": "nvcr.io/nvidia/tensorflow:24.06-tf2-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.10",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "tensorflow",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "classical-ml",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 6818,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tensorflow",
        "documentation": "https://docs.nvidia.com/deeplearning/frameworks/tensorflow-release-notes/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ngc-tensorflow-24-07",
      "name": "nvcr.io/nvidia/tensorflow:24.07-tf2-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.10",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "tensorflow",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "classical-ml",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 7674,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tensorflow",
        "documentation": "https://docs.nvidia.com/deeplearning/frameworks/tensorflow-release-notes/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ngc-tensorflow-24-08",
      "name": "nvcr.io/nvidia/tensorflow:24.08-tf2-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.10",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "tensorflow",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "classical-ml",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 7831,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tensorflow",
        "documentation": "https://docs.nvidia.com/deeplearning/frameworks/tensorflow-release-notes/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ngc-tensorflow-24-09",
      "name": "nvcr.io/nvidia/tensorflow:24.09-tf2-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.10",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "tensorflow",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "classical-ml",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 8334,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tensorflow",
        "documentation": "https://docs.nvidia.com/deeplearning/frameworks/tensorflow-release-notes/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ngc-tensorflow-24-10",
      "name": "nvcr.io/nvidia/tensorflow:24.10-tf2-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.10",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "tensorflow",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "classical-ml",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 8357,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tensorflow",
        "documentation": "https://docs.nvidia.com/deeplearning/frameworks/tensorflow-release-notes/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ngc-tensorflow-24-11",
      "name": "nvcr.io/nvidia/tensorflow:24.11-tf2-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.10",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "tensorflow",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "classical-ml",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 8767,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tensorflow",
        "documentation": "https://docs.nvidia.com/deeplearning/frameworks/tensorflow-release-notes/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ngc-tensorflow-24-12",
      "name": "nvcr.io/nvidia/tensorflow:24.12-tf2-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": {
        "version": "12.6",
        "cudnn": "9.5",
        "min_driver": "560.00",
        "compute_capabilities": [
          "7.0",
          "7.5",
          "8.0",
          "8.6",
          "8.9",
          "9.0"
        ]
      },
      "runtime": {
        "python": "3.10",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "tensorflow",
          "version": "2.17.0"
        },
        {
          "name": "keras",
          "version": "3.4.1"
        },
        {
          "name": "tensorrt",
          "version": "10.7.0"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "classical-ml",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 8710,
        "uncompressed_mb": 22000
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tensorflow",
        "documentation": "https://docs.nvidia.com/deeplearning/frameworks/tensorflow-release-notes/",
        "source": null
      },
      "recommended_for": [
        "Maximum NVIDIA GPU performance with TensorFlow",
        "TensorRT integration",
        "Enterprise TensorFlow training"
      ],
      "system_packages": [
        "git",
        "wget",
        "curl",
        "gcc",
        "g++",
        "make"
      ],
      "notes": "NVIDIA-optimized TensorFlow with TensorRT integration. Volta (V100) support will be discontinued by 25.01 release. Use NVIDIA driver 560+ for best compatibility."
    },
    {
      "id": "ngc-tensorflow-25-01",
      "name": "nvcr.io/nvidia/tensorflow:25.01-tf2-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.10",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "tensorflow",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "classical-ml",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 10654,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tensorflow",
        "documentation": "https://docs.nvidia.com/deeplearning/frameworks/tensorflow-release-notes/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "nvidia-cuda-11-7-cudnn-devel-ubuntu22-04",
      "name": "nvidia/cuda:11.7.1-cudnn8-devel-ubuntu22.04",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2023-11-10",
        "license": "NVIDIA-proprietary"
      },
      "cuda": {
        "version": "11.7",
        "cudnn": "8"
      },
      "runtime": {
        "python": null,
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "base",
        "workloads": [
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 4054,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/nvidia/cuda",
        "documentation": "https://docs.nvidia.com/cuda/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "nvidia-cuda-11-7-cudnn-runtime-ubuntu22-04",
      "name": "nvidia/cuda:11.7.1-cudnn8-runtime-ubuntu22.04",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2023-11-10",
        "license": "NVIDIA-proprietary"
      },
      "cuda": {
        "version": "11.7",
        "cudnn": "8"
      },
      "runtime": {
        "python": null,
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "base",
        "workloads": [
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 1650,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/nvidia/cuda",
        "documentation": "https://docs.nvidia.com/cuda/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "nvidia-cuda-11-7-devel-ubuntu22-04",
      "name": "nvidia/cuda:11.7.1-devel-ubuntu22.04",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2023-11-10",
        "license": "NVIDIA-proprietary"
      },
      "cuda": {
        "version": "11.7"
      },
      "runtime": {
        "python": null,
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "base",
        "workloads": [
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 2961,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/nvidia/cuda",
        "documentation": "https://docs.nvidia.com/cuda/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "nvidia-cuda-11-7-runtime-ubuntu22-04",
      "name": "nvidia/cuda:11.7.1-runtime-ubuntu22.04",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2023-11-10",
        "license": "NVIDIA-proprietary"
      },
      "cuda": {
        "version": "11.7"
      },
      "runtime": {
        "python": null,
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "base",
        "workloads": [
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 1114,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/nvidia/cuda",
        "documentation": "https://docs.nvidia.com/cuda/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "nvidia-cuda-11-8-cudnn-devel-ubuntu20-04",
      "name": "nvidia/cuda:11.8.0-cudnn8-devel-ubuntu20.04",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2023-11-10",
        "license": "NVIDIA-proprietary"
      },
      "cuda": {
        "version": "11.8",
        "cudnn": "8"
      },
      "runtime": {
        "python": null,
        "os": {
          "name": "ubuntu",
          "version": "20.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "base",
        "workloads": [
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 5107,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/nvidia/cuda",
        "documentation": "https://docs.nvidia.com/cuda/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "nvidia-cuda-11-8-cudnn-devel-ubuntu22-04",
      "name": "nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2023-11-10",
        "license": "NVIDIA-proprietary"
      },
      "cuda": {
        "version": "11.8",
        "cudnn": "8"
      },
      "runtime": {
        "python": null,
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "base",
        "workloads": [
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 5115,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/nvidia/cuda",
        "documentation": "https://docs.nvidia.com/cuda/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "nvidia-cuda-11-8-cudnn-runtime-ubuntu20-04",
      "name": "nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu20.04",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2023-11-10",
        "license": "NVIDIA-proprietary"
      },
      "cuda": {
        "version": "11.8",
        "cudnn": "8"
      },
      "runtime": {
        "python": null,
        "os": {
          "name": "ubuntu",
          "version": "20.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "base",
        "workloads": [
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 2080,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/nvidia/cuda",
        "documentation": "https://docs.nvidia.com/cuda/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "nvidia-cuda-11-8-cudnn-runtime-ubuntu22-04",
      "name": "nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu22.04",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2023-11-10",
        "license": "NVIDIA-proprietary"
      },
      "cuda": {
        "version": "11.8",
        "cudnn": "8"
      },
      "runtime": {
        "python": null,
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "base",
        "workloads": [
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 2074,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/nvidia/cuda",
        "documentation": "https://docs.nvidia.com/cuda/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "nvidia-cuda-11-8-devel-ubuntu20-04",
      "name": "nvidia/cuda:11.8.0-devel-ubuntu20.04",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2023-11-10",
        "license": "NVIDIA-proprietary"
      },
      "cuda": {
        "version": "11.8"
      },
      "runtime": {
        "python": null,
        "os": {
          "name": "ubuntu",
          "version": "20.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "base",
        "workloads": [
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 3739,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/nvidia/cuda",
        "documentation": "https://docs.nvidia.com/cuda/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "nvidia-cuda-11-8-devel-ubuntu22-04",
      "name": "nvidia/cuda:11.8.0-devel-ubuntu22.04",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2023-11-10",
        "license": "NVIDIA-proprietary"
      },
      "cuda": {
        "version": "11.8"
      },
      "runtime": {
        "python": null,
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "base",
        "workloads": [
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 3747,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/nvidia/cuda",
        "documentation": "https://docs.nvidia.com/cuda/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "nvidia-cuda-11-8-runtime-ubuntu20-04",
      "name": "nvidia/cuda:11.8.0-runtime-ubuntu20.04",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2023-11-10",
        "license": "NVIDIA-proprietary"
      },
      "cuda": {
        "version": "11.8"
      },
      "runtime": {
        "python": null,
        "os": {
          "name": "ubuntu",
          "version": "20.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "base",
        "workloads": [
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 1407,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/nvidia/cuda",
        "documentation": "https://docs.nvidia.com/cuda/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "nvidia-cuda-11-8-runtime-ubuntu22-04",
      "name": "nvidia/cuda:11.8.0-runtime-ubuntu22.04",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2023-11-10",
        "license": "NVIDIA-proprietary"
      },
      "cuda": {
        "version": "11.8"
      },
      "runtime": {
        "python": null,
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "base",
        "workloads": [
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 1401,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/nvidia/cuda",
        "documentation": "https://docs.nvidia.com/cuda/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "nvidia-cuda-12-1-cudnn-devel-ubuntu22-04",
      "name": "nvidia/cuda:12.1.1-cudnn8-devel-ubuntu22.04",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2023-11-10",
        "license": "NVIDIA-proprietary"
      },
      "cuda": {
        "version": "12.1",
        "cudnn": "8"
      },
      "runtime": {
        "python": null,
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "base",
        "workloads": [
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 5187,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/nvidia/cuda",
        "documentation": "https://docs.nvidia.com/cuda/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "nvidia-cuda-12-1-cudnn-runtime-ubuntu22-04",
      "name": "nvidia/cuda:12.1.1-cudnn8-runtime-ubuntu22.04",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2023-11-10",
        "license": "NVIDIA-proprietary"
      },
      "cuda": {
        "version": "12.1",
        "cudnn": "8"
      },
      "runtime": {
        "python": null,
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "base",
        "workloads": [
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 2044,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/nvidia/cuda",
        "documentation": "https://docs.nvidia.com/cuda/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "nvidia-cuda-12-1-devel-ubuntu22-04",
      "name": "nvidia/cuda:12.1.1-devel-ubuntu22.04",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2023-11-10",
        "license": "NVIDIA-proprietary"
      },
      "cuda": {
        "version": "12.1"
      },
      "runtime": {
        "python": null,
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "base",
        "workloads": [
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 3782,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/nvidia/cuda",
        "documentation": "https://docs.nvidia.com/cuda/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "nvidia-cuda-12-1-runtime-ubuntu22-04",
      "name": "nvidia/cuda:12.1.1-runtime-ubuntu22.04",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2023-11-10",
        "license": "NVIDIA-proprietary"
      },
      "cuda": {
        "version": "12.1"
      },
      "runtime": {
        "python": null,
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "base",
        "workloads": [
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 1353,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/nvidia/cuda",
        "documentation": "https://docs.nvidia.com/cuda/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "nvidia-cuda-12-2-cudnn-devel-ubuntu22-04",
      "name": "nvidia/cuda:12.2.2-cudnn8-devel-ubuntu22.04",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2023-11-21",
        "license": "NVIDIA-proprietary"
      },
      "cuda": {
        "version": "12.2",
        "cudnn": "8"
      },
      "runtime": {
        "python": null,
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "base",
        "workloads": [
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 5088,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/nvidia/cuda",
        "documentation": "https://docs.nvidia.com/cuda/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "nvidia-cuda-12-2-cudnn-runtime-ubuntu22-04",
      "name": "nvidia/cuda:12.2.2-cudnn8-runtime-ubuntu22.04",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2023-11-21",
        "license": "NVIDIA-proprietary"
      },
      "cuda": {
        "version": "12.2",
        "cudnn": "8"
      },
      "runtime": {
        "python": null,
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "base",
        "workloads": [
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 1976,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/nvidia/cuda",
        "documentation": "https://docs.nvidia.com/cuda/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "nvidia-cuda-12-2-devel-ubuntu22-04",
      "name": "nvidia/cuda:12.2.2-devel-ubuntu22.04",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2023-11-21",
        "license": "NVIDIA-proprietary"
      },
      "cuda": {
        "version": "12.2"
      },
      "runtime": {
        "python": null,
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "base",
        "workloads": [
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 3711,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/nvidia/cuda",
        "documentation": "https://docs.nvidia.com/cuda/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "nvidia-cuda-12-2-runtime-ubuntu22-04",
      "name": "nvidia/cuda:12.2.2-runtime-ubuntu22.04",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2023-11-21",
        "license": "NVIDIA-proprietary"
      },
      "cuda": {
        "version": "12.2"
      },
      "runtime": {
        "python": null,
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "base",
        "workloads": [
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 1298,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/nvidia/cuda",
        "documentation": "https://docs.nvidia.com/cuda/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "nvidia-cuda-12-3-cudnn-devel-ubuntu22-04",
      "name": "nvidia/cuda:12.3.2-cudnn9-devel-ubuntu22.04",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-02-28",
        "license": "NVIDIA-proprietary"
      },
      "cuda": {
        "version": "12.3",
        "cudnn": "9"
      },
      "runtime": {
        "python": null,
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "base",
        "workloads": [
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 4408,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/nvidia/cuda",
        "documentation": "https://docs.nvidia.com/cuda/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "nvidia-cuda-12-3-cudnn-runtime-ubuntu22-04",
      "name": "nvidia/cuda:12.3.2-cudnn9-runtime-ubuntu22.04",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-02-28",
        "license": "NVIDIA-proprietary"
      },
      "cuda": {
        "version": "12.3",
        "cudnn": "9"
      },
      "runtime": {
        "python": null,
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "base",
        "workloads": [
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 1958,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/nvidia/cuda",
        "documentation": "https://docs.nvidia.com/cuda/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "nvidia-cuda-12-3-devel-ubuntu22-04",
      "name": "nvidia/cuda:12.3.2-devel-ubuntu22.04",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-02-28",
        "license": "NVIDIA-proprietary"
      },
      "cuda": {
        "version": "12.3"
      },
      "runtime": {
        "python": null,
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "base",
        "workloads": [
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 3764,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/nvidia/cuda",
        "documentation": "https://docs.nvidia.com/cuda/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "nvidia-cuda-12-3-runtime-ubuntu22-04",
      "name": "nvidia/cuda:12.3.2-runtime-ubuntu22.04",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-02-28",
        "license": "NVIDIA-proprietary"
      },
      "cuda": {
        "version": "12.3"
      },
      "runtime": {
        "python": null,
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "base",
        "workloads": [
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 1314,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/nvidia/cuda",
        "documentation": "https://docs.nvidia.com/cuda/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "nvidia-cuda-12-4-cudnn-devel-ubuntu22-04",
      "name": "nvidia/cuda:12.4.1-cudnn-devel-ubuntu22.04",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-04-24",
        "license": "NVIDIA-proprietary"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9",
        "min_driver": "550.54.14",
        "compute_capabilities": [
          "5.0",
          "6.0",
          "7.0",
          "7.5",
          "8.0",
          "8.6",
          "8.9",
          "9.0"
        ]
      },
      "runtime": {
        "python": null,
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "base",
        "workloads": [
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 4561,
        "uncompressed_mb": 10000
      },
      "urls": {
        "registry": "https://hub.docker.com/r/nvidia/cuda",
        "documentation": "https://docs.nvidia.com/cuda/",
        "source": null
      },
      "recommended_for": [
        "Building ML frameworks from source",
        "Custom deep learning development",
        "Full CUDA development environment"
      ],
      "system_packages": [
        "gcc",
        "g++",
        "make"
      ],
      "notes": "Full CUDA development image with cuDNN. Ideal base for building custom ML containers or compiling frameworks from source."
    },
    {
      "id": "nvidia-cuda-12-4-cudnn-runtime-ubuntu22-04",
      "name": "nvidia/cuda:12.4.1-cudnn-runtime-ubuntu22.04",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-04-24",
        "license": "NVIDIA-proprietary"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9"
      },
      "runtime": {
        "python": null,
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "base",
        "workloads": [
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 2037,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/nvidia/cuda",
        "documentation": "https://docs.nvidia.com/cuda/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "nvidia-cuda-12-4-devel-ubuntu22-04",
      "name": "nvidia/cuda:12.4.1-devel-ubuntu22.04",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-04-24",
        "license": "NVIDIA-proprietary"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": null,
        "min_driver": "550.54.14",
        "compute_capabilities": [
          "5.0",
          "6.0",
          "7.0",
          "7.5",
          "8.0",
          "8.6",
          "8.9",
          "9.0"
        ]
      },
      "runtime": {
        "python": null,
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "base",
        "workloads": [
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 3921,
        "uncompressed_mb": 8000
      },
      "urls": {
        "registry": "https://hub.docker.com/r/nvidia/cuda",
        "documentation": "https://docs.nvidia.com/cuda/",
        "source": null
      },
      "recommended_for": [
        "Custom CUDA kernel compilation",
        "Building from source",
        "Development with nvcc"
      ],
      "system_packages": [
        "gcc",
        "g++",
        "make"
      ],
      "notes": "CUDA development image with nvcc compiler. Use for building custom CUDA kernels or compiling PyTorch/TensorFlow from source. Does NOT include cuDNN."
    },
    {
      "id": "nvidia-cuda-12-4-runtime-ubuntu22-04",
      "name": "nvidia/cuda:12.4.1-runtime-ubuntu22.04",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-04-24",
        "license": "NVIDIA-proprietary"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": null,
        "min_driver": "550.54.14",
        "compute_capabilities": [
          "5.0",
          "6.0",
          "7.0",
          "7.5",
          "8.0",
          "8.6",
          "8.9",
          "9.0"
        ]
      },
      "runtime": {
        "python": null,
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "base",
        "workloads": [
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 1398,
        "uncompressed_mb": 2500
      },
      "urls": {
        "registry": "https://hub.docker.com/r/nvidia/cuda",
        "documentation": "https://docs.nvidia.com/cuda/",
        "source": null
      },
      "recommended_for": [
        "Custom ML image base",
        "CUDA application runtime",
        "Minimal CUDA environment"
      ],
      "system_packages": [],
      "notes": "Base CUDA runtime image. Use as FROM base for custom ML containers. Does NOT include cuDNN or Python - add those as needed."
    },
    {
      "id": "nvidia-cuda-12-5-cudnn-devel-ubuntu22-04",
      "name": "nvidia/cuda:12.5.1-cudnn-devel-ubuntu22.04",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-07-13",
        "license": "NVIDIA-proprietary"
      },
      "cuda": {
        "version": "12.5",
        "cudnn": "9"
      },
      "runtime": {
        "python": null,
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "base",
        "workloads": [
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 4315,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/nvidia/cuda",
        "documentation": "https://docs.nvidia.com/cuda/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "nvidia-cuda-12-5-cudnn-runtime-ubuntu22-04",
      "name": "nvidia/cuda:12.5.1-cudnn-runtime-ubuntu22.04",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-07-13",
        "license": "NVIDIA-proprietary"
      },
      "cuda": {
        "version": "12.5",
        "cudnn": "9"
      },
      "runtime": {
        "python": null,
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "base",
        "workloads": [
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 1946,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/nvidia/cuda",
        "documentation": "https://docs.nvidia.com/cuda/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "nvidia-cuda-12-5-devel-ubuntu22-04",
      "name": "nvidia/cuda:12.5.1-devel-ubuntu22.04",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-07-13",
        "license": "NVIDIA-proprietary"
      },
      "cuda": {
        "version": "12.5"
      },
      "runtime": {
        "python": null,
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "base",
        "workloads": [
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 3762,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/nvidia/cuda",
        "documentation": "https://docs.nvidia.com/cuda/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "nvidia-cuda-12-5-devel-ubuntu24-04",
      "name": "nvidia/cuda:12.5.1-devel-ubuntu24.04",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-07-13",
        "license": "NVIDIA-proprietary"
      },
      "cuda": {
        "version": "12.5"
      },
      "runtime": {
        "python": null,
        "os": {
          "name": "ubuntu",
          "version": "24.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "base",
        "workloads": [
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 3416,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/nvidia/cuda",
        "documentation": "https://docs.nvidia.com/cuda/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "nvidia-cuda-12-5-runtime-ubuntu22-04",
      "name": "nvidia/cuda:12.5.1-runtime-ubuntu22.04",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-07-13",
        "license": "NVIDIA-proprietary"
      },
      "cuda": {
        "version": "12.5"
      },
      "runtime": {
        "python": null,
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "base",
        "workloads": [
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 1393,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/nvidia/cuda",
        "documentation": "https://docs.nvidia.com/cuda/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "nvidia-cuda-12-5-runtime-ubuntu24-04",
      "name": "nvidia/cuda:12.5.1-runtime-ubuntu24.04",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-07-13",
        "license": "NVIDIA-proprietary"
      },
      "cuda": {
        "version": "12.5"
      },
      "runtime": {
        "python": null,
        "os": {
          "name": "ubuntu",
          "version": "24.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "base",
        "workloads": [
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 1213,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/nvidia/cuda",
        "documentation": "https://docs.nvidia.com/cuda/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "nvidia-cuda-12-6-devel-ubuntu22-04",
      "name": "nvidia/cuda:12.6.0-devel-ubuntu22.04",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-08-12",
        "license": "NVIDIA-proprietary"
      },
      "cuda": {
        "version": "12.6"
      },
      "runtime": {
        "python": null,
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "base",
        "workloads": [
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 3752,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/nvidia/cuda",
        "documentation": "https://docs.nvidia.com/cuda/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "nvidia-cuda-12-6-devel-ubuntu24-04",
      "name": "nvidia/cuda:12.6.0-devel-ubuntu24.04",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-08-12",
        "license": "NVIDIA-proprietary"
      },
      "cuda": {
        "version": "12.6"
      },
      "runtime": {
        "python": null,
        "os": {
          "name": "ubuntu",
          "version": "24.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "base",
        "workloads": [
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 3768,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/nvidia/cuda",
        "documentation": "https://docs.nvidia.com/cuda/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "nvidia-cuda-12-6-runtime-ubuntu22-04",
      "name": "nvidia/cuda:12.6.0-runtime-ubuntu22.04",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-08-12",
        "license": "NVIDIA-proprietary"
      },
      "cuda": {
        "version": "12.6"
      },
      "runtime": {
        "python": null,
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "base",
        "workloads": [
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 1395,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/nvidia/cuda",
        "documentation": "https://docs.nvidia.com/cuda/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "nvidia-cuda-12-6-runtime-ubuntu24-04",
      "name": "nvidia/cuda:12.6.0-runtime-ubuntu24.04",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-08-12",
        "license": "NVIDIA-proprietary"
      },
      "cuda": {
        "version": "12.6"
      },
      "runtime": {
        "python": null,
        "os": {
          "name": "ubuntu",
          "version": "24.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "base",
        "workloads": [
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 1398,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/nvidia/cuda",
        "documentation": "https://docs.nvidia.com/cuda/",
        "source": null
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ollama-0-4-6",
      "name": "ollama/ollama:0.4.6",
      "metadata": {
        "status": "official",
        "provider": "ollama",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-11-28",
        "license": "MIT"
      },
      "cuda": {
        "version": "12.4"
      },
      "runtime": {
        "python": null,
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "ollama",
          "version": "0.4.6"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia",
          "amd"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 1801,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/ollama/ollama",
        "documentation": "https://ollama.ai/",
        "source": "https://github.com/ollama/ollama"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ollama-0-4-7",
      "name": "ollama/ollama:0.4.7",
      "metadata": {
        "status": "official",
        "provider": "ollama",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-11-30",
        "license": "MIT"
      },
      "cuda": {
        "version": "12.4"
      },
      "runtime": {
        "python": null,
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "ollama",
          "version": "0.4.7"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia",
          "amd"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 1801,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/ollama/ollama",
        "documentation": "https://ollama.ai/",
        "source": "https://github.com/ollama/ollama"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ollama-0-5-0",
      "name": "ollama/ollama:0.5.0",
      "metadata": {
        "status": "official",
        "provider": "ollama",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-12-06",
        "license": "MIT"
      },
      "cuda": {
        "version": "12.4"
      },
      "runtime": {
        "python": null,
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "ollama",
          "version": "0.5.0"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia",
          "amd"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 1801,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/ollama/ollama",
        "documentation": "https://ollama.ai/",
        "source": "https://github.com/ollama/ollama"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ollama-0-5-1",
      "name": "ollama/ollama:0.5.1",
      "metadata": {
        "status": "official",
        "provider": "ollama",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-12-06",
        "license": "MIT"
      },
      "cuda": {
        "version": "12.4"
      },
      "runtime": {
        "python": null,
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "ollama",
          "version": "0.5.1"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia",
          "amd"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 1801,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/ollama/ollama",
        "documentation": "https://ollama.ai/",
        "source": "https://github.com/ollama/ollama"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ollama-0-5-2",
      "name": "ollama/ollama:0.5.2",
      "metadata": {
        "status": "official",
        "provider": "ollama",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-12-14",
        "license": "MIT"
      },
      "cuda": {
        "version": "12.4"
      },
      "runtime": {
        "python": null,
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "ollama",
          "version": "0.5.2"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia",
          "amd"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 1528,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/ollama/ollama",
        "documentation": "https://ollama.ai/",
        "source": "https://github.com/ollama/ollama"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ollama-0-5-3",
      "name": "ollama/ollama:0.5.3",
      "metadata": {
        "status": "official",
        "provider": "ollama",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-12-17",
        "license": "MIT"
      },
      "cuda": {
        "version": "12.4"
      },
      "runtime": {
        "python": null,
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "ollama",
          "version": "0.5.3"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia",
          "amd"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 1528,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/ollama/ollama",
        "documentation": "https://ollama.ai/",
        "source": "https://github.com/ollama/ollama"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ollama-0-5-4",
      "name": "ollama/ollama:0.5.4",
      "metadata": {
        "status": "official",
        "provider": "ollama",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-12-17",
        "license": "MIT"
      },
      "cuda": {
        "version": "12.4"
      },
      "runtime": {
        "python": null,
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "ollama",
          "version": "0.5.4"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia",
          "amd"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 1528,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/ollama/ollama",
        "documentation": "https://ollama.ai/",
        "source": "https://github.com/ollama/ollama"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "ollama-latest",
      "name": "ollama/ollama:latest",
      "metadata": {
        "status": "official",
        "provider": "ollama",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2025-12-02",
        "license": "MIT"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": null,
        "min_driver": "531.00",
        "compute_capabilities": [
          "5.0",
          "6.0",
          "7.0",
          "7.5",
          "8.0",
          "8.6",
          "8.9",
          "9.0"
        ]
      },
      "runtime": {
        "python": null,
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "ollama",
          "version": "0.5.4"
        },
        {
          "name": "llama.cpp",
          "version": "latest"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia",
          "amd"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 1961,
        "uncompressed_mb": 3500
      },
      "urls": {
        "registry": "https://hub.docker.com/r/ollama/ollama",
        "documentation": "https://ollama.ai/",
        "source": "https://github.com/ollama/ollama"
      },
      "recommended_for": [
        "Local LLM inference",
        "Easy model management",
        "Development and prototyping"
      ],
      "system_packages": [],
      "notes": "Lightweight LLM runner. Run with: docker run --gpus all -v ollama:/root/.ollama -p 11434:11434 ollama/ollama. Supports NVIDIA (compute 5.0+) and AMD GPUs."
    },
    {
      "id": "pytorch-2-1-2-cuda11-8-devel",
      "name": "pytorch/pytorch:2.1.2-cuda11.8-cudnn8-devel",
      "metadata": {
        "status": "official",
        "provider": "pytorch",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2023-12-19",
        "license": "BSD-3-Clause"
      },
      "cuda": {
        "version": "11.8",
        "cudnn": "8"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "2.1.2"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 8685,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/pytorch/pytorch",
        "documentation": "https://pytorch.org/docs/stable/",
        "source": "https://github.com/pytorch/pytorch"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "pytorch-2-1-2-cuda11-8-runtime",
      "name": "pytorch/pytorch:2.1.2-cuda11.8-cudnn8-runtime",
      "metadata": {
        "status": "official",
        "provider": "pytorch",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2023-12-19",
        "license": "BSD-3-Clause"
      },
      "cuda": {
        "version": "11.8",
        "cudnn": "8"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "2.1.2"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 3612,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/pytorch/pytorch",
        "documentation": "https://pytorch.org/docs/stable/",
        "source": "https://github.com/pytorch/pytorch"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "pytorch-2-1-2-cuda12-1-devel",
      "name": "pytorch/pytorch:2.1.2-cuda12.1-cudnn8-devel",
      "metadata": {
        "status": "official",
        "provider": "pytorch",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2023-12-15",
        "license": "BSD-3-Clause"
      },
      "cuda": {
        "version": "12.1",
        "cudnn": "8"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "2.1.2"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 8452,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/pytorch/pytorch",
        "documentation": "https://pytorch.org/docs/stable/",
        "source": "https://github.com/pytorch/pytorch"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "pytorch-2-1-2-cuda12-1-runtime",
      "name": "pytorch/pytorch:2.1.2-cuda12.1-cudnn8-runtime",
      "metadata": {
        "status": "official",
        "provider": "pytorch",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2023-12-15",
        "license": "BSD-3-Clause"
      },
      "cuda": {
        "version": "12.1",
        "cudnn": "8"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "2.1.2"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 3322,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/pytorch/pytorch",
        "documentation": "https://pytorch.org/docs/stable/",
        "source": "https://github.com/pytorch/pytorch"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "pytorch-2-2-2-cuda11-8-devel",
      "name": "pytorch/pytorch:2.2.2-cuda11.8-cudnn8-devel",
      "metadata": {
        "status": "official",
        "provider": "pytorch",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-03-27",
        "license": "BSD-3-Clause"
      },
      "cuda": {
        "version": "11.8",
        "cudnn": "8"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "2.2.2"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 8897,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/pytorch/pytorch",
        "documentation": "https://pytorch.org/docs/stable/",
        "source": "https://github.com/pytorch/pytorch"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "pytorch-2-2-2-cuda11-8-runtime",
      "name": "pytorch/pytorch:2.2.2-cuda11.8-cudnn8-runtime",
      "metadata": {
        "status": "official",
        "provider": "pytorch",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-03-27",
        "license": "BSD-3-Clause"
      },
      "cuda": {
        "version": "11.8",
        "cudnn": "8"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "2.2.2"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 3815,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/pytorch/pytorch",
        "documentation": "https://pytorch.org/docs/stable/",
        "source": "https://github.com/pytorch/pytorch"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "pytorch-2-2-2-cuda12-1-devel",
      "name": "pytorch/pytorch:2.2.2-cuda12.1-cudnn8-devel",
      "metadata": {
        "status": "official",
        "provider": "pytorch",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-03-27",
        "license": "BSD-3-Clause"
      },
      "cuda": {
        "version": "12.1",
        "cudnn": "8"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "2.2.2"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 8674,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/pytorch/pytorch",
        "documentation": "https://pytorch.org/docs/stable/",
        "source": "https://github.com/pytorch/pytorch"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "pytorch-2-2-2-cuda12-1-runtime",
      "name": "pytorch/pytorch:2.2.2-cuda12.1-cudnn8-runtime",
      "metadata": {
        "status": "official",
        "provider": "pytorch",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-03-27",
        "license": "BSD-3-Clause"
      },
      "cuda": {
        "version": "12.1",
        "cudnn": "8"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "2.2.2"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 3521,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/pytorch/pytorch",
        "documentation": "https://pytorch.org/docs/stable/",
        "source": "https://github.com/pytorch/pytorch"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "pytorch-2-3-0-cuda11-8-devel",
      "name": "pytorch/pytorch:2.3.0-cuda11.8-cudnn8-devel",
      "metadata": {
        "status": "official",
        "provider": "pytorch",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-04-29",
        "license": "BSD-3-Clause"
      },
      "cuda": {
        "version": "11.8",
        "cudnn": "8"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "2.3.0"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 8937,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/pytorch/pytorch",
        "documentation": "https://pytorch.org/docs/stable/",
        "source": "https://github.com/pytorch/pytorch"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "pytorch-2-3-0-cuda11-8-runtime",
      "name": "pytorch/pytorch:2.3.0-cuda11.8-cudnn8-runtime",
      "metadata": {
        "status": "official",
        "provider": "pytorch",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-04-29",
        "license": "BSD-3-Clause"
      },
      "cuda": {
        "version": "11.8",
        "cudnn": "8"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "2.3.0"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 3860,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/pytorch/pytorch",
        "documentation": "https://pytorch.org/docs/stable/",
        "source": "https://github.com/pytorch/pytorch"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "pytorch-2-3-0-cuda12-1-devel",
      "name": "pytorch/pytorch:2.3.0-cuda12.1-cudnn8-devel",
      "metadata": {
        "status": "official",
        "provider": "pytorch",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-04-29",
        "license": "BSD-3-Clause"
      },
      "cuda": {
        "version": "12.1",
        "cudnn": "8"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "2.3.0"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 8705,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/pytorch/pytorch",
        "documentation": "https://pytorch.org/docs/stable/",
        "source": "https://github.com/pytorch/pytorch"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "pytorch-2-3-0-cuda12-1-runtime",
      "name": "pytorch/pytorch:2.3.0-cuda12.1-cudnn8-runtime",
      "metadata": {
        "status": "official",
        "provider": "pytorch",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-04-29",
        "license": "BSD-3-Clause"
      },
      "cuda": {
        "version": "12.1",
        "cudnn": "8"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "2.3.0"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 3557,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/pytorch/pytorch",
        "documentation": "https://pytorch.org/docs/stable/",
        "source": "https://github.com/pytorch/pytorch"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "pytorch-2-3-1-cuda11-8-devel",
      "name": "pytorch/pytorch:2.3.1-cuda11.8-cudnn8-devel",
      "metadata": {
        "status": "official",
        "provider": "pytorch",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-06-05",
        "license": "BSD-3-Clause"
      },
      "cuda": {
        "version": "11.8",
        "cudnn": "8"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "2.3.1"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 8935,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/pytorch/pytorch",
        "documentation": "https://pytorch.org/docs/stable/",
        "source": "https://github.com/pytorch/pytorch"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "pytorch-2-3-1-cuda11-8-runtime",
      "name": "pytorch/pytorch:2.3.1-cuda11.8-cudnn8-runtime",
      "metadata": {
        "status": "official",
        "provider": "pytorch",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-06-05",
        "license": "BSD-3-Clause"
      },
      "cuda": {
        "version": "11.8",
        "cudnn": "8"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "2.3.1"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 3854,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/pytorch/pytorch",
        "documentation": "https://pytorch.org/docs/stable/",
        "source": "https://github.com/pytorch/pytorch"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "pytorch-2-3-1-cuda12-1-devel",
      "name": "pytorch/pytorch:2.3.1-cuda12.1-cudnn8-devel",
      "metadata": {
        "status": "official",
        "provider": "pytorch",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-06-05",
        "license": "BSD-3-Clause"
      },
      "cuda": {
        "version": "12.1",
        "cudnn": "8"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "2.3.1"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 8704,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/pytorch/pytorch",
        "documentation": "https://pytorch.org/docs/stable/",
        "source": "https://github.com/pytorch/pytorch"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "pytorch-2-3-1-cuda12-1-runtime",
      "name": "pytorch/pytorch:2.3.1-cuda12.1-cudnn8-runtime",
      "metadata": {
        "status": "official",
        "provider": "pytorch",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-06-05",
        "license": "BSD-3-Clause"
      },
      "cuda": {
        "version": "12.1",
        "cudnn": "8"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "2.3.1"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 3551,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/pytorch/pytorch",
        "documentation": "https://pytorch.org/docs/stable/",
        "source": "https://github.com/pytorch/pytorch"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "pytorch-2-4-0-cuda11-8-devel",
      "name": "pytorch/pytorch:2.4.0-cuda11.8-cudnn9-devel",
      "metadata": {
        "status": "official",
        "provider": "pytorch",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-07-24",
        "license": "BSD-3-Clause"
      },
      "cuda": {
        "version": "11.8",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "2.4.0"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 7673,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/pytorch/pytorch",
        "documentation": "https://pytorch.org/docs/stable/",
        "source": "https://github.com/pytorch/pytorch"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "pytorch-2-4-0-cuda11-8-runtime",
      "name": "pytorch/pytorch:2.4.0-cuda11.8-cudnn9-runtime",
      "metadata": {
        "status": "official",
        "provider": "pytorch",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-07-24",
        "license": "BSD-3-Clause"
      },
      "cuda": {
        "version": "11.8",
        "cudnn": "9",
        "min_driver": "520.61.05",
        "compute_capabilities": [
          "3.5",
          "5.0",
          "6.0",
          "7.0",
          "7.5",
          "8.0",
          "8.6",
          "8.9",
          "9.0"
        ]
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "2.4.0"
        },
        {
          "name": "torchvision",
          "version": "0.19.0"
        },
        {
          "name": "torchaudio",
          "version": "2.4.0"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 3959,
        "uncompressed_mb": 8000
      },
      "urls": {
        "registry": "https://hub.docker.com/r/pytorch/pytorch",
        "documentation": "https://pytorch.org/docs/stable/",
        "source": "https://github.com/pytorch/pytorch"
      },
      "recommended_for": [
        "Legacy CUDA 11.8 compatibility",
        "Older GPU driver support",
        "Wider GPU architecture support (Kepler+)"
      ],
      "system_packages": [
        "git",
        "wget",
        "curl"
      ],
      "notes": "CUDA 11.8 variant for systems with older drivers or requiring broader GPU compatibility. Supports older Kepler architecture (compute capability 3.5+)."
    },
    {
      "id": "pytorch-2-4-0-cuda12-1-devel",
      "name": "pytorch/pytorch:2.4.0-cuda12.1-cudnn9-devel",
      "metadata": {
        "status": "official",
        "provider": "pytorch",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-07-24",
        "license": "BSD-3-Clause"
      },
      "cuda": {
        "version": "12.1",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "2.4.0"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 7402,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/pytorch/pytorch",
        "documentation": "https://pytorch.org/docs/stable/",
        "source": "https://github.com/pytorch/pytorch"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "pytorch-2-4-0-cuda12-1-runtime",
      "name": "pytorch/pytorch:2.4.0-cuda12.1-cudnn9-runtime",
      "metadata": {
        "status": "official",
        "provider": "pytorch",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-07-24",
        "license": "BSD-3-Clause"
      },
      "cuda": {
        "version": "12.1",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "2.4.0"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 3653,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/pytorch/pytorch",
        "documentation": "https://pytorch.org/docs/stable/",
        "source": "https://github.com/pytorch/pytorch"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "pytorch-2-4-0-cuda12-4-devel",
      "name": "pytorch/pytorch:2.4.0-cuda12.4-cudnn9-devel",
      "metadata": {
        "status": "official",
        "provider": "pytorch",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-07-24",
        "license": "BSD-3-Clause"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "2.4.0"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 7604,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/pytorch/pytorch",
        "documentation": "https://pytorch.org/docs/stable/",
        "source": "https://github.com/pytorch/pytorch"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "pytorch-2-4-0-cuda12-4-runtime",
      "name": "pytorch/pytorch:2.4.0-cuda12.4-cudnn9-runtime",
      "metadata": {
        "status": "official",
        "provider": "pytorch",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-07-24",
        "license": "BSD-3-Clause"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "2.4.0"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 3746,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/pytorch/pytorch",
        "documentation": "https://pytorch.org/docs/stable/",
        "source": "https://github.com/pytorch/pytorch"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "pytorch-2-4-1-cuda11-8-devel",
      "name": "pytorch/pytorch:2.4.1-cuda11.8-cudnn9-devel",
      "metadata": {
        "status": "official",
        "provider": "pytorch",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-09-04",
        "license": "BSD-3-Clause"
      },
      "cuda": {
        "version": "11.8",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "2.4.1"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 6788,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/pytorch/pytorch",
        "documentation": "https://pytorch.org/docs/stable/",
        "source": "https://github.com/pytorch/pytorch"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "pytorch-2-4-1-cuda11-8-runtime",
      "name": "pytorch/pytorch:2.4.1-cuda11.8-cudnn9-runtime",
      "metadata": {
        "status": "official",
        "provider": "pytorch",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-09-04",
        "license": "BSD-3-Clause"
      },
      "cuda": {
        "version": "11.8",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "2.4.1"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 3074,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/pytorch/pytorch",
        "documentation": "https://pytorch.org/docs/stable/",
        "source": "https://github.com/pytorch/pytorch"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "pytorch-2-4-1-cuda12-1-devel",
      "name": "pytorch/pytorch:2.4.1-cuda12.1-cudnn9-devel",
      "metadata": {
        "status": "official",
        "provider": "pytorch",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-09-04",
        "license": "BSD-3-Clause"
      },
      "cuda": {
        "version": "12.1",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "2.4.1"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 6758,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/pytorch/pytorch",
        "documentation": "https://pytorch.org/docs/stable/",
        "source": "https://github.com/pytorch/pytorch"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "pytorch-2-4-1-cuda12-1-runtime",
      "name": "pytorch/pytorch:2.4.1-cuda12.1-cudnn9-runtime",
      "metadata": {
        "status": "official",
        "provider": "pytorch",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-09-04",
        "license": "BSD-3-Clause"
      },
      "cuda": {
        "version": "12.1",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "2.4.1"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 3009,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/pytorch/pytorch",
        "documentation": "https://pytorch.org/docs/stable/",
        "source": "https://github.com/pytorch/pytorch"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "pytorch-2-4-1-cuda12-4-devel",
      "name": "pytorch/pytorch:2.4.1-cuda12.4-cudnn9-devel",
      "metadata": {
        "status": "official",
        "provider": "pytorch",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-09-04",
        "license": "BSD-3-Clause"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "2.4.1"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 6922,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/pytorch/pytorch",
        "documentation": "https://pytorch.org/docs/stable/",
        "source": "https://github.com/pytorch/pytorch"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "pytorch-2-4-1-cuda12-4-runtime",
      "name": "pytorch/pytorch:2.4.1-cuda12.4-cudnn9-runtime",
      "metadata": {
        "status": "official",
        "provider": "pytorch",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-09-04",
        "license": "BSD-3-Clause"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "2.4.1"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 3064,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/pytorch/pytorch",
        "documentation": "https://pytorch.org/docs/stable/",
        "source": "https://github.com/pytorch/pytorch"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "pytorch-2-5-0-cuda11-8-devel",
      "name": "pytorch/pytorch:2.5.0-cuda11.8-cudnn9-devel",
      "metadata": {
        "status": "official",
        "provider": "pytorch",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-10-17",
        "license": "BSD-3-Clause"
      },
      "cuda": {
        "version": "11.8",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "2.5.0"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 6774,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/pytorch/pytorch",
        "documentation": "https://pytorch.org/docs/stable/",
        "source": "https://github.com/pytorch/pytorch"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "pytorch-2-5-0-cuda11-8-runtime",
      "name": "pytorch/pytorch:2.5.0-cuda11.8-cudnn9-runtime",
      "metadata": {
        "status": "official",
        "provider": "pytorch",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-10-17",
        "license": "BSD-3-Clause"
      },
      "cuda": {
        "version": "11.8",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "2.5.0"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 3060,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/pytorch/pytorch",
        "documentation": "https://pytorch.org/docs/stable/",
        "source": "https://github.com/pytorch/pytorch"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "pytorch-2-5-0-cuda12-1-devel",
      "name": "pytorch/pytorch:2.5.0-cuda12.1-cudnn9-devel",
      "metadata": {
        "status": "official",
        "provider": "pytorch",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-10-17",
        "license": "BSD-3-Clause"
      },
      "cuda": {
        "version": "12.1",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "2.5.0"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 6752,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/pytorch/pytorch",
        "documentation": "https://pytorch.org/docs/stable/",
        "source": "https://github.com/pytorch/pytorch"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "pytorch-2-5-0-cuda12-1-runtime",
      "name": "pytorch/pytorch:2.5.0-cuda12.1-cudnn9-runtime",
      "metadata": {
        "status": "official",
        "provider": "pytorch",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-10-17",
        "license": "BSD-3-Clause"
      },
      "cuda": {
        "version": "12.1",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "2.5.0"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 3002,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/pytorch/pytorch",
        "documentation": "https://pytorch.org/docs/stable/",
        "source": "https://github.com/pytorch/pytorch"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "pytorch-2-5-0-cuda12-4-devel",
      "name": "pytorch/pytorch:2.5.0-cuda12.4-cudnn9-devel",
      "metadata": {
        "status": "official",
        "provider": "pytorch",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-10-17",
        "license": "BSD-3-Clause"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "2.5.0"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 7069,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/pytorch/pytorch",
        "documentation": "https://pytorch.org/docs/stable/",
        "source": "https://github.com/pytorch/pytorch"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "pytorch-2-5-0-cuda12-4-runtime",
      "name": "pytorch/pytorch:2.5.0-cuda12.4-cudnn9-runtime",
      "metadata": {
        "status": "official",
        "provider": "pytorch",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-10-17",
        "license": "BSD-3-Clause"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "2.5.0"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 3181,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/pytorch/pytorch",
        "documentation": "https://pytorch.org/docs/stable/",
        "source": "https://github.com/pytorch/pytorch"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "pytorch-2-5-1-cuda11-8-devel",
      "name": "pytorch/pytorch:2.5.1-cuda11.8-cudnn9-devel",
      "metadata": {
        "status": "official",
        "provider": "pytorch",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-10-29",
        "license": "BSD-3-Clause"
      },
      "cuda": {
        "version": "11.8",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "2.5.1"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 6776,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/pytorch/pytorch",
        "documentation": "https://pytorch.org/docs/stable/",
        "source": "https://github.com/pytorch/pytorch"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "pytorch-2-5-1-cuda11-8-runtime",
      "name": "pytorch/pytorch:2.5.1-cuda11.8-cudnn9-runtime",
      "metadata": {
        "status": "official",
        "provider": "pytorch",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-10-29",
        "license": "BSD-3-Clause"
      },
      "cuda": {
        "version": "11.8",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "2.5.1"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 3061,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/pytorch/pytorch",
        "documentation": "https://pytorch.org/docs/stable/",
        "source": "https://github.com/pytorch/pytorch"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "pytorch-2-5-1-cuda12-1-devel",
      "name": "pytorch/pytorch:2.5.1-cuda12.1-cudnn9-devel",
      "metadata": {
        "status": "official",
        "provider": "pytorch",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-10-29",
        "license": "BSD-3-Clause"
      },
      "cuda": {
        "version": "12.1",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "2.5.1"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 6753,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/pytorch/pytorch",
        "documentation": "https://pytorch.org/docs/stable/",
        "source": "https://github.com/pytorch/pytorch"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "pytorch-2-5-1-cuda12-1-runtime",
      "name": "pytorch/pytorch:2.5.1-cuda12.1-cudnn9-runtime",
      "metadata": {
        "status": "official",
        "provider": "pytorch",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-10-29",
        "license": "BSD-3-Clause"
      },
      "cuda": {
        "version": "12.1",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "2.5.1"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 3004,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/pytorch/pytorch",
        "documentation": "https://pytorch.org/docs/stable/",
        "source": "https://github.com/pytorch/pytorch"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "pytorch-2-5-1-cuda12-4-devel",
      "name": "pytorch/pytorch:2.5.1-cuda12.4-cudnn9-devel",
      "metadata": {
        "status": "official",
        "provider": "pytorch",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-10-29",
        "license": "BSD-3-Clause"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9",
        "min_driver": "550.54.14",
        "compute_capabilities": [
          "5.0",
          "6.0",
          "7.0",
          "7.5",
          "8.0",
          "8.6",
          "8.9",
          "9.0"
        ]
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "2.5.1"
        },
        {
          "name": "torchvision",
          "version": "0.20.1"
        },
        {
          "name": "torchaudio",
          "version": "2.5.1"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 7071,
        "uncompressed_mb": 14000
      },
      "urls": {
        "registry": "https://hub.docker.com/r/pytorch/pytorch",
        "documentation": "https://pytorch.org/docs/stable/",
        "source": "https://github.com/pytorch/pytorch"
      },
      "recommended_for": [
        "Custom CUDA kernel development",
        "PyTorch extension compilation",
        "Research requiring nvcc compiler"
      ],
      "system_packages": [
        "git",
        "wget",
        "curl",
        "gcc",
        "g++",
        "make"
      ],
      "notes": "Development variant with CUDA compiler (nvcc). Use this for custom CUDA kernels, torch.compile with Triton, or PyTorch extensions requiring compilation."
    },
    {
      "id": "pytorch-2-5-1-cuda12-4-runtime",
      "name": "pytorch/pytorch:2.5.1-cuda12.4-cudnn9-runtime",
      "metadata": {
        "status": "official",
        "provider": "pytorch",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-10-29",
        "license": "BSD-3-Clause"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9",
        "min_driver": "550.54.14",
        "compute_capabilities": [
          "5.0",
          "6.0",
          "7.0",
          "7.5",
          "8.0",
          "8.6",
          "8.9",
          "9.0"
        ]
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "2.5.1"
        },
        {
          "name": "torchvision",
          "version": "0.20.1"
        },
        {
          "name": "torchaudio",
          "version": "2.5.1"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 3183,
        "uncompressed_mb": 8500
      },
      "urls": {
        "registry": "https://hub.docker.com/r/pytorch/pytorch",
        "documentation": "https://pytorch.org/docs/stable/",
        "source": "https://github.com/pytorch/pytorch"
      },
      "recommended_for": [
        "PyTorch training on NVIDIA GPUs",
        "General deep learning development",
        "LLM fine-tuning"
      ],
      "system_packages": [
        "git",
        "wget",
        "curl"
      ],
      "notes": "Official PyTorch image with CUDA 12.4 runtime. Use -devel variant if you need to compile custom CUDA kernels."
    },
    {
      "id": "pytorch-2-6-0-cuda11-8-devel",
      "name": "pytorch/pytorch:2.6.0-cuda11.8-cudnn9-devel",
      "metadata": {
        "status": "official",
        "provider": "pytorch",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2025-01-29",
        "license": "BSD-3-Clause"
      },
      "cuda": {
        "version": "11.8",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "2.6.0"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 6753,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/pytorch/pytorch",
        "documentation": "https://pytorch.org/docs/stable/",
        "source": "https://github.com/pytorch/pytorch"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "pytorch-2-6-0-cuda11-8-runtime",
      "name": "pytorch/pytorch:2.6.0-cuda11.8-cudnn9-runtime",
      "metadata": {
        "status": "official",
        "provider": "pytorch",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2025-01-29",
        "license": "BSD-3-Clause"
      },
      "cuda": {
        "version": "11.8",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "2.6.0"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 3039,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/pytorch/pytorch",
        "documentation": "https://pytorch.org/docs/stable/",
        "source": "https://github.com/pytorch/pytorch"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "pytorch-2-6-0-cuda12-4-devel",
      "name": "pytorch/pytorch:2.6.0-cuda12.4-cudnn9-devel",
      "metadata": {
        "status": "official",
        "provider": "pytorch",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2025-01-29",
        "license": "BSD-3-Clause"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "2.6.0"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 7048,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/pytorch/pytorch",
        "documentation": "https://pytorch.org/docs/stable/",
        "source": "https://github.com/pytorch/pytorch"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "pytorch-2-6-0-cuda12-4-runtime",
      "name": "pytorch/pytorch:2.6.0-cuda12.4-cudnn9-runtime",
      "metadata": {
        "status": "official",
        "provider": "pytorch",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2025-01-29",
        "license": "BSD-3-Clause"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "2.6.0"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 3160,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/pytorch/pytorch",
        "documentation": "https://pytorch.org/docs/stable/",
        "source": "https://github.com/pytorch/pytorch"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "pytorch-2-6-0-cuda12-6-devel",
      "name": "pytorch/pytorch:2.6.0-cuda12.6-cudnn9-devel",
      "metadata": {
        "status": "official",
        "provider": "pytorch",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2025-01-29",
        "license": "BSD-3-Clause"
      },
      "cuda": {
        "version": "12.6",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "2.6.0"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "devel",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 6964,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/pytorch/pytorch",
        "documentation": "https://pytorch.org/docs/stable/",
        "source": "https://github.com/pytorch/pytorch"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "pytorch-2-6-0-cuda12-6-runtime",
      "name": "pytorch/pytorch:2.6.0-cuda12.6-cudnn9-runtime",
      "metadata": {
        "status": "official",
        "provider": "pytorch",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2025-01-29",
        "license": "BSD-3-Clause"
      },
      "cuda": {
        "version": "12.6",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "pytorch",
          "version": "2.6.0"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "training",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 3122,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/pytorch/pytorch",
        "documentation": "https://pytorch.org/docs/stable/",
        "source": "https://github.com/pytorch/pytorch"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tensorflow-2-15-0-cpu",
      "name": "tensorflow/tensorflow:2.15.0",
      "metadata": {
        "status": "official",
        "provider": "tensorflow",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2023-11-21",
        "license": "Apache-2.0"
      },
      "cuda": null,
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "tensorflow",
          "version": "2.15.0"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "none"
        ],
        "image_type": "runtime",
        "role": "training",
        "workloads": [
          "classical-ml",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 510,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/tensorflow/tensorflow",
        "documentation": "https://www.tensorflow.org/install/docker",
        "source": "https://github.com/tensorflow/tensorflow"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tensorflow-2-15-0-gpu",
      "name": "tensorflow/tensorflow:2.15.0-gpu",
      "metadata": {
        "status": "official",
        "provider": "tensorflow",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2023-11-21",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.3",
        "cudnn": "8.9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "tensorflow",
          "version": "2.15.0"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "training",
        "workloads": [
          "classical-ml",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 3526,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/tensorflow/tensorflow",
        "documentation": "https://www.tensorflow.org/install/docker",
        "source": "https://github.com/tensorflow/tensorflow"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tensorflow-2-15-0-gpu-jupyter",
      "name": "tensorflow/tensorflow:2.15.0-gpu-jupyter",
      "metadata": {
        "status": "official",
        "provider": "tensorflow",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2023-11-21",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.3",
        "cudnn": "8.9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "tensorflow",
          "version": "2.15.0"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "notebook",
        "workloads": [
          "classical-ml",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 3641,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/tensorflow/tensorflow",
        "documentation": "https://www.tensorflow.org/install/docker",
        "source": "https://github.com/tensorflow/tensorflow"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tensorflow-2-16-1-cpu",
      "name": "tensorflow/tensorflow:2.16.1",
      "metadata": {
        "status": "official",
        "provider": "tensorflow",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-03-09",
        "license": "Apache-2.0"
      },
      "cuda": null,
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "tensorflow",
          "version": "2.16.1"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "none"
        ],
        "image_type": "runtime",
        "role": "training",
        "workloads": [
          "classical-ml",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 523,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/tensorflow/tensorflow",
        "documentation": "https://www.tensorflow.org/install/docker",
        "source": "https://github.com/tensorflow/tensorflow"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tensorflow-2-16-1-gpu",
      "name": "tensorflow/tensorflow:2.16.1-gpu",
      "metadata": {
        "status": "official",
        "provider": "tensorflow",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-03-09",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.3",
        "cudnn": "8.9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "tensorflow",
          "version": "2.16.1"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "training",
        "workloads": [
          "classical-ml",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 3641,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/tensorflow/tensorflow",
        "documentation": "https://www.tensorflow.org/install/docker",
        "source": "https://github.com/tensorflow/tensorflow"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tensorflow-2-16-1-gpu-jupyter",
      "name": "tensorflow/tensorflow:2.16.1-gpu-jupyter",
      "metadata": {
        "status": "official",
        "provider": "tensorflow",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-03-09",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.3",
        "cudnn": "8.9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "tensorflow",
          "version": "2.16.1"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "notebook",
        "workloads": [
          "classical-ml",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 3759,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/tensorflow/tensorflow",
        "documentation": "https://www.tensorflow.org/install/docker",
        "source": "https://github.com/tensorflow/tensorflow"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tensorflow-2-16-2-cpu",
      "name": "tensorflow/tensorflow:2.16.2",
      "metadata": {
        "status": "official",
        "provider": "tensorflow",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-06-29",
        "license": "Apache-2.0"
      },
      "cuda": null,
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "tensorflow",
          "version": "2.16.2"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "none"
        ],
        "image_type": "runtime",
        "role": "training",
        "workloads": [
          "classical-ml",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 527,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/tensorflow/tensorflow",
        "documentation": "https://www.tensorflow.org/install/docker",
        "source": "https://github.com/tensorflow/tensorflow"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tensorflow-2-16-2-gpu",
      "name": "tensorflow/tensorflow:2.16.2-gpu",
      "metadata": {
        "status": "official",
        "provider": "tensorflow",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-06-29",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.3",
        "cudnn": "8.9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "tensorflow",
          "version": "2.16.2"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "training",
        "workloads": [
          "classical-ml",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 3646,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/tensorflow/tensorflow",
        "documentation": "https://www.tensorflow.org/install/docker",
        "source": "https://github.com/tensorflow/tensorflow"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tensorflow-2-16-2-gpu-jupyter",
      "name": "tensorflow/tensorflow:2.16.2-gpu-jupyter",
      "metadata": {
        "status": "official",
        "provider": "tensorflow",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-06-29",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.3",
        "cudnn": "8.9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "tensorflow",
          "version": "2.16.2"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "notebook",
        "workloads": [
          "classical-ml",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 3762,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/tensorflow/tensorflow",
        "documentation": "https://www.tensorflow.org/install/docker",
        "source": "https://github.com/tensorflow/tensorflow"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tensorflow-2-17-0-cpu",
      "name": "tensorflow/tensorflow:2.17.0",
      "metadata": {
        "status": "official",
        "provider": "tensorflow",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-07-12",
        "license": "Apache-2.0"
      },
      "cuda": null,
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "tensorflow",
          "version": "2.17.0"
        },
        {
          "name": "keras",
          "version": "3.4.1"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "none"
        ],
        "image_type": "runtime",
        "role": "training",
        "workloads": [
          "classical-ml",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 534,
        "uncompressed_mb": 3200
      },
      "urls": {
        "registry": "https://hub.docker.com/r/tensorflow/tensorflow",
        "documentation": "https://www.tensorflow.org/install/docker",
        "source": "https://github.com/tensorflow/tensorflow"
      },
      "recommended_for": [
        "CPU-only inference",
        "Development without GPU",
        "CI/CD pipelines"
      ],
      "system_packages": [
        "git",
        "wget",
        "curl"
      ],
      "notes": "CPU-only TensorFlow image. Much smaller than GPU variant. Good for inference or development on machines without NVIDIA GPUs."
    },
    {
      "id": "tensorflow-2-17-0-gpu",
      "name": "tensorflow/tensorflow:2.17.0-gpu",
      "metadata": {
        "status": "official",
        "provider": "tensorflow",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-07-12",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.3",
        "cudnn": "8.9",
        "min_driver": "545.23.06",
        "compute_capabilities": [
          "5.0",
          "6.0",
          "7.0",
          "7.5",
          "8.0",
          "8.6",
          "8.9",
          "9.0"
        ]
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "tensorflow",
          "version": "2.17.0"
        },
        {
          "name": "keras",
          "version": "3.4.1"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "training",
        "workloads": [
          "classical-ml",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 3656,
        "uncompressed_mb": 7800
      },
      "urls": {
        "registry": "https://hub.docker.com/r/tensorflow/tensorflow",
        "documentation": "https://www.tensorflow.org/install/docker",
        "source": "https://github.com/tensorflow/tensorflow"
      },
      "recommended_for": [
        "TensorFlow training on NVIDIA GPUs",
        "Keras deep learning projects",
        "Production ML pipelines"
      ],
      "system_packages": [
        "git",
        "wget",
        "curl"
      ],
      "notes": "Official TensorFlow GPU image. For Jupyter support, use tensorflow/tensorflow:2.17.0-gpu-jupyter variant."
    },
    {
      "id": "tensorflow-2-17-0-gpu-jupyter",
      "name": "tensorflow/tensorflow:2.17.0-gpu-jupyter",
      "metadata": {
        "status": "official",
        "provider": "tensorflow",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-07-12",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.3",
        "cudnn": "8.9",
        "min_driver": "545.23.06",
        "compute_capabilities": [
          "5.0",
          "6.0",
          "7.0",
          "7.5",
          "8.0",
          "8.6",
          "8.9",
          "9.0"
        ]
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "tensorflow",
          "version": "2.17.0"
        },
        {
          "name": "keras",
          "version": "3.4.1"
        },
        {
          "name": "jupyter",
          "version": "1.0.0"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "notebook",
        "workloads": [
          "classical-ml",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 3772,
        "uncompressed_mb": 8500
      },
      "urls": {
        "registry": "https://hub.docker.com/r/tensorflow/tensorflow",
        "documentation": "https://www.tensorflow.org/install/docker",
        "source": "https://github.com/tensorflow/tensorflow"
      },
      "recommended_for": [
        "Interactive TensorFlow development",
        "GPU-accelerated notebooks",
        "Data science experimentation"
      ],
      "system_packages": [
        "git",
        "wget",
        "curl"
      ],
      "notes": "TensorFlow GPU image with Jupyter notebook server. Start with: docker run --gpus all -p 8888:8888 tensorflow/tensorflow:2.17.0-gpu-jupyter"
    },
    {
      "id": "tensorflow-2-18-0-cpu",
      "name": "tensorflow/tensorflow:2.18.0",
      "metadata": {
        "status": "official",
        "provider": "tensorflow",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-10-25",
        "license": "Apache-2.0"
      },
      "cuda": null,
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "tensorflow",
          "version": "2.18.0"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "none"
        ],
        "image_type": "runtime",
        "role": "training",
        "workloads": [
          "classical-ml",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 548,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/tensorflow/tensorflow",
        "documentation": "https://www.tensorflow.org/install/docker",
        "source": "https://github.com/tensorflow/tensorflow"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tensorflow-2-18-0-gpu",
      "name": "tensorflow/tensorflow:2.18.0-gpu",
      "metadata": {
        "status": "official",
        "provider": "tensorflow",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-10-25",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.3",
        "cudnn": "8.9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "tensorflow",
          "version": "2.18.0"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "training",
        "workloads": [
          "classical-ml",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 3681,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/tensorflow/tensorflow",
        "documentation": "https://www.tensorflow.org/install/docker",
        "source": "https://github.com/tensorflow/tensorflow"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tensorflow-2-18-0-gpu-jupyter",
      "name": "tensorflow/tensorflow:2.18.0-gpu-jupyter",
      "metadata": {
        "status": "official",
        "provider": "tensorflow",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-10-25",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.3",
        "cudnn": "8.9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "tensorflow",
          "version": "2.18.0"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "notebook",
        "workloads": [
          "classical-ml",
          "computer-vision",
          "nlp",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 3799,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/tensorflow/tensorflow",
        "documentation": "https://www.tensorflow.org/install/docker",
        "source": "https://github.com/tensorflow/tensorflow"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tgi-1-4-0",
      "name": "ghcr.io/huggingface/text-generation-inference:1.4.0",
      "metadata": {
        "status": "official",
        "provider": "huggingface",
        "registry": "ghcr",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "text-generation-inference",
          "version": "1.4.0"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 4123,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://github.com/huggingface/text-generation-inference/pkgs/container/text-generation-inference",
        "documentation": "https://huggingface.co/docs/text-generation-inference",
        "source": "https://github.com/huggingface/text-generation-inference"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tgi-1-4-4",
      "name": "ghcr.io/huggingface/text-generation-inference:1.4.4",
      "metadata": {
        "status": "official",
        "provider": "huggingface",
        "registry": "ghcr",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "text-generation-inference",
          "version": "1.4.4"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 4258,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://github.com/huggingface/text-generation-inference/pkgs/container/text-generation-inference",
        "documentation": "https://huggingface.co/docs/text-generation-inference",
        "source": "https://github.com/huggingface/text-generation-inference"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tgi-1-4-5",
      "name": "ghcr.io/huggingface/text-generation-inference:1.4.5",
      "metadata": {
        "status": "official",
        "provider": "huggingface",
        "registry": "ghcr",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "text-generation-inference",
          "version": "1.4.5"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 4258,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://github.com/huggingface/text-generation-inference/pkgs/container/text-generation-inference",
        "documentation": "https://huggingface.co/docs/text-generation-inference",
        "source": "https://github.com/huggingface/text-generation-inference"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tgi-2-0-0",
      "name": "ghcr.io/huggingface/text-generation-inference:2.0.0",
      "metadata": {
        "status": "official",
        "provider": "huggingface",
        "registry": "ghcr",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "text-generation-inference",
          "version": "2.0.0"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 4342,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://github.com/huggingface/text-generation-inference/pkgs/container/text-generation-inference",
        "documentation": "https://huggingface.co/docs/text-generation-inference",
        "source": "https://github.com/huggingface/text-generation-inference"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tgi-2-0-1",
      "name": "ghcr.io/huggingface/text-generation-inference:2.0.1",
      "metadata": {
        "status": "official",
        "provider": "huggingface",
        "registry": "ghcr",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "text-generation-inference",
          "version": "2.0.1"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 4345,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://github.com/huggingface/text-generation-inference/pkgs/container/text-generation-inference",
        "documentation": "https://huggingface.co/docs/text-generation-inference",
        "source": "https://github.com/huggingface/text-generation-inference"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tgi-2-0-2",
      "name": "ghcr.io/huggingface/text-generation-inference:2.0.2",
      "metadata": {
        "status": "official",
        "provider": "huggingface",
        "registry": "ghcr",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "text-generation-inference",
          "version": "2.0.2"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 4576,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://github.com/huggingface/text-generation-inference/pkgs/container/text-generation-inference",
        "documentation": "https://huggingface.co/docs/text-generation-inference",
        "source": "https://github.com/huggingface/text-generation-inference"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tgi-2-0-3",
      "name": "ghcr.io/huggingface/text-generation-inference:2.0.3",
      "metadata": {
        "status": "official",
        "provider": "huggingface",
        "registry": "ghcr",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "text-generation-inference",
          "version": "2.0.3"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 4523,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://github.com/huggingface/text-generation-inference/pkgs/container/text-generation-inference",
        "documentation": "https://huggingface.co/docs/text-generation-inference",
        "source": "https://github.com/huggingface/text-generation-inference"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tgi-2-0-4",
      "name": "ghcr.io/huggingface/text-generation-inference:2.0.4",
      "metadata": {
        "status": "official",
        "provider": "huggingface",
        "registry": "ghcr",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "text-generation-inference",
          "version": "2.0.4"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 4526,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://github.com/huggingface/text-generation-inference/pkgs/container/text-generation-inference",
        "documentation": "https://huggingface.co/docs/text-generation-inference",
        "source": "https://github.com/huggingface/text-generation-inference"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tgi-2-1-0",
      "name": "ghcr.io/huggingface/text-generation-inference:2.1.0",
      "metadata": {
        "status": "official",
        "provider": "huggingface",
        "registry": "ghcr",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "text-generation-inference",
          "version": "2.1.0"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 4540,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://github.com/huggingface/text-generation-inference/pkgs/container/text-generation-inference",
        "documentation": "https://huggingface.co/docs/text-generation-inference",
        "source": "https://github.com/huggingface/text-generation-inference"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tgi-2-2-0",
      "name": "ghcr.io/huggingface/text-generation-inference:2.2.0",
      "metadata": {
        "status": "official",
        "provider": "huggingface",
        "registry": "ghcr",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "text-generation-inference",
          "version": "2.2.0"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 4990,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://github.com/huggingface/text-generation-inference/pkgs/container/text-generation-inference",
        "documentation": "https://huggingface.co/docs/text-generation-inference",
        "source": "https://github.com/huggingface/text-generation-inference"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tgi-2-3-0",
      "name": "ghcr.io/huggingface/text-generation-inference:2.3.0",
      "metadata": {
        "status": "official",
        "provider": "huggingface",
        "registry": "ghcr",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "text-generation-inference",
          "version": "2.3.0"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 6592,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://github.com/huggingface/text-generation-inference/pkgs/container/text-generation-inference",
        "documentation": "https://huggingface.co/docs/text-generation-inference",
        "source": "https://github.com/huggingface/text-generation-inference"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tgi-2-3-1",
      "name": "ghcr.io/huggingface/text-generation-inference:2.3.1",
      "metadata": {
        "status": "official",
        "provider": "huggingface",
        "registry": "ghcr",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "text-generation-inference",
          "version": "2.3.1"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 6579,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://github.com/huggingface/text-generation-inference/pkgs/container/text-generation-inference",
        "documentation": "https://huggingface.co/docs/text-generation-inference",
        "source": "https://github.com/huggingface/text-generation-inference"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tgi-2-4-0",
      "name": "ghcr.io/huggingface/text-generation-inference:2.4.0",
      "metadata": {
        "status": "official",
        "provider": "huggingface",
        "registry": "ghcr",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "text-generation-inference",
          "version": "2.4.0"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 6676,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://github.com/huggingface/text-generation-inference/pkgs/container/text-generation-inference",
        "documentation": "https://huggingface.co/docs/text-generation-inference",
        "source": "https://github.com/huggingface/text-generation-inference"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tgi-2-4-1",
      "name": "ghcr.io/huggingface/text-generation-inference:2.4.1",
      "metadata": {
        "status": "official",
        "provider": "huggingface",
        "registry": "ghcr",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "text-generation-inference",
          "version": "2.4.1"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 6596,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://github.com/huggingface/text-generation-inference/pkgs/container/text-generation-inference",
        "documentation": "https://huggingface.co/docs/text-generation-inference",
        "source": "https://github.com/huggingface/text-generation-inference"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tgi-3-0-0",
      "name": "ghcr.io/huggingface/text-generation-inference:3.0.0",
      "metadata": {
        "status": "official",
        "provider": "huggingface",
        "registry": "ghcr",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "text-generation-inference",
          "version": "3.0.0"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 6614,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://github.com/huggingface/text-generation-inference/pkgs/container/text-generation-inference",
        "documentation": "https://huggingface.co/docs/text-generation-inference",
        "source": "https://github.com/huggingface/text-generation-inference"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tgi-3-0-1",
      "name": "ghcr.io/huggingface/text-generation-inference:3.0.1",
      "metadata": {
        "status": "official",
        "provider": "huggingface",
        "registry": "ghcr",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "text-generation-inference",
          "version": "3.0.1"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 6614,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://github.com/huggingface/text-generation-inference/pkgs/container/text-generation-inference",
        "documentation": "https://huggingface.co/docs/text-generation-inference",
        "source": "https://github.com/huggingface/text-generation-inference"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tgi-3-1-0",
      "name": "ghcr.io/huggingface/text-generation-inference:3.1.0",
      "metadata": {
        "status": "official",
        "provider": "huggingface",
        "registry": "ghcr",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "text-generation-inference",
          "version": "3.1.0"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 5426,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://github.com/huggingface/text-generation-inference/pkgs/container/text-generation-inference",
        "documentation": "https://huggingface.co/docs/text-generation-inference",
        "source": "https://github.com/huggingface/text-generation-inference"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tgi-3-1-1",
      "name": "ghcr.io/huggingface/text-generation-inference:3.1.1",
      "metadata": {
        "status": "official",
        "provider": "huggingface",
        "registry": "ghcr",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "text-generation-inference",
          "version": "3.1.1"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 8223,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://github.com/huggingface/text-generation-inference/pkgs/container/text-generation-inference",
        "documentation": "https://huggingface.co/docs/text-generation-inference",
        "source": "https://github.com/huggingface/text-generation-inference"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tgi-3-2-0",
      "name": "ghcr.io/huggingface/text-generation-inference:3.2.0",
      "metadata": {
        "status": "official",
        "provider": "huggingface",
        "registry": "ghcr",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "text-generation-inference",
          "version": "3.2.0"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 8224,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://github.com/huggingface/text-generation-inference/pkgs/container/text-generation-inference",
        "documentation": "https://huggingface.co/docs/text-generation-inference",
        "source": "https://github.com/huggingface/text-generation-inference"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tgi-3-2-1",
      "name": "ghcr.io/huggingface/text-generation-inference:3.2.1",
      "metadata": {
        "status": "official",
        "provider": "huggingface",
        "registry": "ghcr",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "text-generation-inference",
          "version": "3.2.1"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 8223,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://github.com/huggingface/text-generation-inference/pkgs/container/text-generation-inference",
        "documentation": "https://huggingface.co/docs/text-generation-inference",
        "source": "https://github.com/huggingface/text-generation-inference"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tgi-3-2-2",
      "name": "ghcr.io/huggingface/text-generation-inference:3.2.2",
      "metadata": {
        "status": "official",
        "provider": "huggingface",
        "registry": "ghcr",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "text-generation-inference",
          "version": "3.2.2"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 5361,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://github.com/huggingface/text-generation-inference/pkgs/container/text-generation-inference",
        "documentation": "https://huggingface.co/docs/text-generation-inference",
        "source": "https://github.com/huggingface/text-generation-inference"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tgi-3-3-0",
      "name": "ghcr.io/huggingface/text-generation-inference:3.3.0",
      "metadata": {
        "status": "official",
        "provider": "huggingface",
        "registry": "ghcr",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "text-generation-inference",
          "version": "3.3.0"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 6105,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://github.com/huggingface/text-generation-inference/pkgs/container/text-generation-inference",
        "documentation": "https://huggingface.co/docs/text-generation-inference",
        "source": "https://github.com/huggingface/text-generation-inference"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tgi-3-3-1",
      "name": "ghcr.io/huggingface/text-generation-inference:3.3.1",
      "metadata": {
        "status": "official",
        "provider": "huggingface",
        "registry": "ghcr",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "text-generation-inference",
          "version": "3.3.1"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 8675,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://github.com/huggingface/text-generation-inference/pkgs/container/text-generation-inference",
        "documentation": "https://huggingface.co/docs/text-generation-inference",
        "source": "https://github.com/huggingface/text-generation-inference"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tgi-3-3-2",
      "name": "ghcr.io/huggingface/text-generation-inference:3.3.2",
      "metadata": {
        "status": "official",
        "provider": "huggingface",
        "registry": "ghcr",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "text-generation-inference",
          "version": "3.3.2"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 8675,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://github.com/huggingface/text-generation-inference/pkgs/container/text-generation-inference",
        "documentation": "https://huggingface.co/docs/text-generation-inference",
        "source": "https://github.com/huggingface/text-generation-inference"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tgi-3-3-3",
      "name": "ghcr.io/huggingface/text-generation-inference:3.3.3",
      "metadata": {
        "status": "official",
        "provider": "huggingface",
        "registry": "ghcr",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "text-generation-inference",
          "version": "3.3.3"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 8679,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://github.com/huggingface/text-generation-inference/pkgs/container/text-generation-inference",
        "documentation": "https://huggingface.co/docs/text-generation-inference",
        "source": "https://github.com/huggingface/text-generation-inference"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tgi-3-3-4",
      "name": "ghcr.io/huggingface/text-generation-inference:3.3.4",
      "metadata": {
        "status": "official",
        "provider": "huggingface",
        "registry": "ghcr",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "text-generation-inference",
          "version": "3.3.4"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 8679,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://github.com/huggingface/text-generation-inference/pkgs/container/text-generation-inference",
        "documentation": "https://huggingface.co/docs/text-generation-inference",
        "source": "https://github.com/huggingface/text-generation-inference"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tgi-3-3-5",
      "name": "ghcr.io/huggingface/text-generation-inference:3.3.5",
      "metadata": {
        "status": "official",
        "provider": "huggingface",
        "registry": "ghcr",
        "maintenance": "active",
        "last_updated": "2025-01-15",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9",
        "min_driver": "550.54.14",
        "compute_capabilities": [
          "7.0",
          "7.5",
          "8.0",
          "8.6",
          "8.9",
          "9.0"
        ]
      },
      "runtime": {
        "python": "3.11",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "text-generation-inference",
          "version": "3.3.5"
        },
        {
          "name": "transformers",
          "version": "4.47.0"
        },
        {
          "name": "pytorch",
          "version": "2.5.1"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 4200,
        "uncompressed_mb": 11000
      },
      "urls": {
        "registry": "https://github.com/huggingface/text-generation-inference/pkgs/container/text-generation-inference",
        "documentation": "https://huggingface.co/docs/text-generation-inference",
        "source": "https://github.com/huggingface/text-generation-inference"
      },
      "recommended_for": [
        "High-throughput LLM inference",
        "Hugging Face model serving",
        "Production LLM APIs"
      ],
      "system_packages": [],
      "notes": "Hugging Face Text Generation Inference server. Optimized for H100, A100, A10G and T4 GPUs with CUDA 12.2+. Supports flash attention and continuous batching."
    },
    {
      "id": "tritonserver-23-12-py3",
      "name": "nvcr.io/nvidia/tritonserver:23.12-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.12",
        "os": {
          "name": "ubuntu",
          "version": "24.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "triton-inference-server",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "multimodal",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 7363,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tritonserver",
        "documentation": "https://docs.nvidia.com/deeplearning/triton-inference-server/",
        "source": "https://github.com/triton-inference-server/server"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tritonserver-24-01-py3",
      "name": "nvcr.io/nvidia/tritonserver:24.01-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.12",
        "os": {
          "name": "ubuntu",
          "version": "24.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "triton-inference-server",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "multimodal",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 7370,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tritonserver",
        "documentation": "https://docs.nvidia.com/deeplearning/triton-inference-server/",
        "source": "https://github.com/triton-inference-server/server"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tritonserver-24-02-py3",
      "name": "nvcr.io/nvidia/tritonserver:24.02-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.12",
        "os": {
          "name": "ubuntu",
          "version": "24.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "triton-inference-server",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "multimodal",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 7114,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tritonserver",
        "documentation": "https://docs.nvidia.com/deeplearning/triton-inference-server/",
        "source": "https://github.com/triton-inference-server/server"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tritonserver-24-03-py3",
      "name": "nvcr.io/nvidia/tritonserver:24.03-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.12",
        "os": {
          "name": "ubuntu",
          "version": "24.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "triton-inference-server",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "multimodal",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 7510,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tritonserver",
        "documentation": "https://docs.nvidia.com/deeplearning/triton-inference-server/",
        "source": "https://github.com/triton-inference-server/server"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tritonserver-24-04-py3",
      "name": "nvcr.io/nvidia/tritonserver:24.04-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.12",
        "os": {
          "name": "ubuntu",
          "version": "24.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "triton-inference-server",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "multimodal",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 7500,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tritonserver",
        "documentation": "https://docs.nvidia.com/deeplearning/triton-inference-server/",
        "source": "https://github.com/triton-inference-server/server"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tritonserver-24-05-py3",
      "name": "nvcr.io/nvidia/tritonserver:24.05-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.12",
        "os": {
          "name": "ubuntu",
          "version": "24.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "triton-inference-server",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "multimodal",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 7734,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tritonserver",
        "documentation": "https://docs.nvidia.com/deeplearning/triton-inference-server/",
        "source": "https://github.com/triton-inference-server/server"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tritonserver-24-06-py3",
      "name": "nvcr.io/nvidia/tritonserver:24.06-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.12",
        "os": {
          "name": "ubuntu",
          "version": "24.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "triton-inference-server",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "multimodal",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 7818,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tritonserver",
        "documentation": "https://docs.nvidia.com/deeplearning/triton-inference-server/",
        "source": "https://github.com/triton-inference-server/server"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tritonserver-24-07-py3",
      "name": "nvcr.io/nvidia/tritonserver:24.07-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.12",
        "os": {
          "name": "ubuntu",
          "version": "24.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "triton-inference-server",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "multimodal",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 8453,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tritonserver",
        "documentation": "https://docs.nvidia.com/deeplearning/triton-inference-server/",
        "source": "https://github.com/triton-inference-server/server"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tritonserver-24-08-py3",
      "name": "nvcr.io/nvidia/tritonserver:24.08-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.12",
        "os": {
          "name": "ubuntu",
          "version": "24.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "triton-inference-server",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "multimodal",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 8735,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tritonserver",
        "documentation": "https://docs.nvidia.com/deeplearning/triton-inference-server/",
        "source": "https://github.com/triton-inference-server/server"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tritonserver-24-09-py3",
      "name": "nvcr.io/nvidia/tritonserver:24.09-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.12",
        "os": {
          "name": "ubuntu",
          "version": "24.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "triton-inference-server",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "multimodal",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 8775,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tritonserver",
        "documentation": "https://docs.nvidia.com/deeplearning/triton-inference-server/",
        "source": "https://github.com/triton-inference-server/server"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tritonserver-24-10-py3",
      "name": "nvcr.io/nvidia/tritonserver:24.10-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.12",
        "os": {
          "name": "ubuntu",
          "version": "24.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "triton-inference-server",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "multimodal",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 8816,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tritonserver",
        "documentation": "https://docs.nvidia.com/deeplearning/triton-inference-server/",
        "source": "https://github.com/triton-inference-server/server"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tritonserver-24-11-py3",
      "name": "nvcr.io/nvidia/tritonserver:24.11-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.12",
        "os": {
          "name": "ubuntu",
          "version": "24.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "triton-inference-server",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "multimodal",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 9052,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tritonserver",
        "documentation": "https://docs.nvidia.com/deeplearning/triton-inference-server/",
        "source": "https://github.com/triton-inference-server/server"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tritonserver-24-12-py3",
      "name": "nvcr.io/nvidia/tritonserver:24.12-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.12",
        "os": {
          "name": "ubuntu",
          "version": "24.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "triton-inference-server",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "multimodal",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 9182,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tritonserver",
        "documentation": "https://docs.nvidia.com/deeplearning/triton-inference-server/",
        "source": "https://github.com/triton-inference-server/server"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tritonserver-25-01-py3",
      "name": "nvcr.io/nvidia/tritonserver:25.01-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": null,
      "runtime": {
        "python": "3.12",
        "os": {
          "name": "ubuntu",
          "version": "24.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "triton-inference-server",
          "version": "varies-by-release"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "multimodal",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 11673,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tritonserver",
        "documentation": "https://docs.nvidia.com/deeplearning/triton-inference-server/",
        "source": "https://github.com/triton-inference-server/server"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "tritonserver-25-11-py3",
      "name": "nvcr.io/nvidia/tritonserver:25.11-py3",
      "metadata": {
        "status": "official",
        "provider": "nvidia-ngc",
        "registry": "ngc",
        "maintenance": "active",
        "last_updated": "2025-12-08",
        "license": "NVIDIA-proprietary"
      },
      "cuda": {
        "version": "12.9",
        "cudnn": "9",
        "min_driver": "560.00",
        "compute_capabilities": [
          "7.0",
          "7.5",
          "8.0",
          "8.6",
          "8.9",
          "9.0"
        ]
      },
      "runtime": {
        "python": "3.12",
        "os": {
          "name": "ubuntu",
          "version": "24.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "triton-inference-server",
          "version": "2.63.0"
        },
        {
          "name": "tensorrt",
          "version": "10.11.0"
        },
        {
          "name": "pytorch",
          "version": "2.9.0"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm",
          "computer-vision",
          "nlp",
          "multimodal",
          "generic"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 7285,
        "uncompressed_mb": 22000
      },
      "urls": {
        "registry": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tritonserver",
        "documentation": "https://docs.nvidia.com/deeplearning/triton-inference-server/",
        "source": "https://github.com/triton-inference-server/server"
      },
      "recommended_for": [
        "Multi-model serving",
        "Enterprise ML inference",
        "High-performance model deployment"
      ],
      "system_packages": [],
      "notes": "NVIDIA Triton Inference Server supports multiple frameworks (PyTorch, TensorFlow, ONNX, TensorRT) and provides dynamic batching, model versioning, and ensemble models."
    },
    {
      "id": "vllm-openai-latest",
      "name": "vllm/vllm-openai:latest",
      "metadata": {
        "status": "official",
        "provider": "vllm",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2025-12-03",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9",
        "min_driver": "550.54.14",
        "compute_capabilities": [
          "7.0",
          "7.5",
          "8.0",
          "8.6",
          "8.9",
          "9.0"
        ]
      },
      "runtime": {
        "python": "3.12",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64",
          "arm64"
        ]
      },
      "frameworks": [
        {
          "name": "vllm",
          "version": "0.6.4"
        },
        {
          "name": "pytorch",
          "version": "2.5.1"
        },
        {
          "name": "transformers",
          "version": "4.47.0"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 8517,
        "uncompressed_mb": 12000
      },
      "urls": {
        "registry": "https://hub.docker.com/r/vllm/vllm-openai",
        "documentation": "https://docs.vllm.ai/en/latest/",
        "source": "https://github.com/vllm-project/vllm"
      },
      "recommended_for": [
        "High-throughput LLM inference",
        "OpenAI-compatible API serving",
        "Production LLM deployment"
      ],
      "system_packages": [],
      "notes": "Production-ready LLM inference server with OpenAI-compatible API. Supports continuous batching and PagedAttention for optimal GPU utilization."
    },
    {
      "id": "vllm-openai-v0-4-2",
      "name": "vllm/vllm-openai:v0.4.2",
      "metadata": {
        "status": "official",
        "provider": "vllm",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-05-05",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.12",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "vllm",
          "version": "0.4.2"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 3963,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/vllm/vllm-openai",
        "documentation": "https://docs.vllm.ai/en/latest/",
        "source": "https://github.com/vllm-project/vllm"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "vllm-openai-v0-4-3",
      "name": "vllm/vllm-openai:v0.4.3",
      "metadata": {
        "status": "official",
        "provider": "vllm",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-06-01",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.12",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "vllm",
          "version": "0.4.3"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 3752,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/vllm/vllm-openai",
        "documentation": "https://docs.vllm.ai/en/latest/",
        "source": "https://github.com/vllm-project/vllm"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "vllm-openai-v0-5-0",
      "name": "vllm/vllm-openai:v0.5.0",
      "metadata": {
        "status": "official",
        "provider": "vllm",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-06-12",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.12",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "vllm",
          "version": "0.5.0"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 3756,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/vllm/vllm-openai",
        "documentation": "https://docs.vllm.ai/en/latest/",
        "source": "https://github.com/vllm-project/vllm"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "vllm-openai-v0-5-1",
      "name": "vllm/vllm-openai:v0.5.1",
      "metadata": {
        "status": "official",
        "provider": "vllm",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-07-06",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.12",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "vllm",
          "version": "0.5.1"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 5488,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/vllm/vllm-openai",
        "documentation": "https://docs.vllm.ai/en/latest/",
        "source": "https://github.com/vllm-project/vllm"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "vllm-openai-v0-5-2",
      "name": "vllm/vllm-openai:v0.5.2",
      "metadata": {
        "status": "official",
        "provider": "vllm",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-07-15",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.12",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "vllm",
          "version": "0.5.2"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 5313,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/vllm/vllm-openai",
        "documentation": "https://docs.vllm.ai/en/latest/",
        "source": "https://github.com/vllm-project/vllm"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "vllm-openai-v0-5-3",
      "name": "vllm/vllm-openai:v0.5.3",
      "metadata": {
        "status": "official",
        "provider": "vllm",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-07-23",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.12",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "vllm",
          "version": "0.5.3"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 5329,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/vllm/vllm-openai",
        "documentation": "https://docs.vllm.ai/en/latest/",
        "source": "https://github.com/vllm-project/vllm"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "vllm-openai-v0-5-4",
      "name": "vllm/vllm-openai:v0.5.4",
      "metadata": {
        "status": "official",
        "provider": "vllm",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-08-05",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.12",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "vllm",
          "version": "0.5.4"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 5227,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/vllm/vllm-openai",
        "documentation": "https://docs.vllm.ai/en/latest/",
        "source": "https://github.com/vllm-project/vllm"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "vllm-openai-v0-5-5",
      "name": "vllm/vllm-openai:v0.5.5",
      "metadata": {
        "status": "official",
        "provider": "vllm",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-08-23",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.12",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "vllm",
          "version": "0.5.5"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 5193,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/vllm/vllm-openai",
        "documentation": "https://docs.vllm.ai/en/latest/",
        "source": "https://github.com/vllm-project/vllm"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "vllm-openai-v0-6-0",
      "name": "vllm/vllm-openai:v0.6.0",
      "metadata": {
        "status": "official",
        "provider": "vllm",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-09-05",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.12",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "vllm",
          "version": "0.6.0"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 4975,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/vllm/vllm-openai",
        "documentation": "https://docs.vllm.ai/en/latest/",
        "source": "https://github.com/vllm-project/vllm"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "vllm-openai-v0-6-1",
      "name": "vllm/vllm-openai:v0.6.1",
      "metadata": {
        "status": "official",
        "provider": "vllm",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-09-11",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.12",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "vllm",
          "version": "0.6.1"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 5015,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/vllm/vllm-openai",
        "documentation": "https://docs.vllm.ai/en/latest/",
        "source": "https://github.com/vllm-project/vllm"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "vllm-openai-v0-6-2",
      "name": "vllm/vllm-openai:v0.6.2",
      "metadata": {
        "status": "official",
        "provider": "vllm",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-09-25",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.12",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "vllm",
          "version": "0.6.2"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 5114,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/vllm/vllm-openai",
        "documentation": "https://docs.vllm.ai/en/latest/",
        "source": "https://github.com/vllm-project/vllm"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "vllm-openai-v0-6-3",
      "name": "vllm/vllm-openai:v0.6.3",
      "metadata": {
        "status": "official",
        "provider": "vllm",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-10-14",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.12",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "vllm",
          "version": "0.6.3"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 5187,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/vllm/vllm-openai",
        "documentation": "https://docs.vllm.ai/en/latest/",
        "source": "https://github.com/vllm-project/vllm"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "vllm-openai-v0-6-4",
      "name": "vllm/vllm-openai:v0.6.4",
      "metadata": {
        "status": "official",
        "provider": "vllm",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-11-15",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.12",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "vllm",
          "version": "0.6.4"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 5363,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/vllm/vllm-openai",
        "documentation": "https://docs.vllm.ai/en/latest/",
        "source": "https://github.com/vllm-project/vllm"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "vllm-openai-v0-6-5",
      "name": "vllm/vllm-openai:v0.6.5",
      "metadata": {
        "status": "official",
        "provider": "vllm",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-12-18",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.12",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "vllm",
          "version": "0.6.5"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 5208,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/vllm/vllm-openai",
        "documentation": "https://docs.vllm.ai/en/latest/",
        "source": "https://github.com/vllm-project/vllm"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    },
    {
      "id": "vllm-openai-v0-6-6",
      "name": "vllm/vllm-openai:v0.6.6",
      "metadata": {
        "status": "official",
        "provider": "vllm",
        "registry": "dockerhub",
        "maintenance": "active",
        "last_updated": "2024-12-27",
        "license": "Apache-2.0"
      },
      "cuda": {
        "version": "12.4",
        "cudnn": "9"
      },
      "runtime": {
        "python": "3.12",
        "os": {
          "name": "ubuntu",
          "version": "22.04"
        },
        "architectures": [
          "amd64"
        ]
      },
      "frameworks": [
        {
          "name": "vllm",
          "version": "0.6.6"
        }
      ],
      "capabilities": {
        "gpu_vendors": [
          "nvidia"
        ],
        "image_type": "runtime",
        "role": "serving",
        "workloads": [
          "llm"
        ]
      },
      "cloud": {
        "affinity": [
          "any"
        ],
        "exclusive_to": null,
        "aws_ami": null,
        "gcp_image": null,
        "azure_image": null
      },
      "security": null,
      "size": {
        "compressed_mb": 5256,
        "uncompressed_mb": null
      },
      "urls": {
        "registry": "https://hub.docker.com/r/vllm/vllm-openai",
        "documentation": "https://docs.vllm.ai/en/latest/",
        "source": "https://github.com/vllm-project/vllm"
      },
      "recommended_for": [],
      "system_packages": [],
      "notes": null
    }
  ]
}
