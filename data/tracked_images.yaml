# GPU Doctor - Tracked Image Configuration
# This file defines which Docker images are tracked for automatic catalog updates.
#
# Each entry specifies:
#   - id: Internal grouping identifier
#   - namespace/org: The container namespace or organization
#   - repo: Repository name
#   - parser: Tag parser to use (maps to functions in tag_parsers.py)
#   - tags: Explicit tags to track
#   - discover: (optional) Auto-discover new tags matching a pattern

dockerhub:
  # ==========================================================================
  # PyTorch Official Images
  # ==========================================================================
  - id: pytorch-cuda
    namespace: pytorch
    repo: pytorch
    parser: pytorch_cuda
    tags:
      # PyTorch 2.6.x (latest stable)
      - "2.6.0-cuda12.4-cudnn9-runtime"
      - "2.6.0-cuda12.4-cudnn9-devel"
      - "2.6.0-cuda12.1-cudnn9-runtime"
      - "2.6.0-cuda12.1-cudnn9-devel"
      - "2.6.0-cuda11.8-cudnn9-runtime"
      - "2.6.0-cuda11.8-cudnn9-devel"
      # PyTorch 2.5.x
      - "2.5.1-cuda12.4-cudnn9-runtime"
      - "2.5.1-cuda12.4-cudnn9-devel"
      - "2.5.1-cuda12.1-cudnn9-runtime"
      - "2.5.1-cuda12.1-cudnn9-devel"
      - "2.5.1-cuda11.8-cudnn9-runtime"
      - "2.5.1-cuda11.8-cudnn9-devel"
      - "2.5.0-cuda12.4-cudnn9-runtime"
      - "2.5.0-cuda12.4-cudnn9-devel"
      - "2.5.0-cuda12.1-cudnn9-runtime"
      - "2.5.0-cuda12.1-cudnn9-devel"
      - "2.5.0-cuda11.8-cudnn9-runtime"
      - "2.5.0-cuda11.8-cudnn9-devel"
      # PyTorch 2.4.x
      - "2.4.1-cuda12.4-cudnn9-runtime"
      - "2.4.1-cuda12.4-cudnn9-devel"
      - "2.4.1-cuda12.1-cudnn9-runtime"
      - "2.4.1-cuda12.1-cudnn9-devel"
      - "2.4.1-cuda11.8-cudnn9-runtime"
      - "2.4.1-cuda11.8-cudnn9-devel"
      - "2.4.0-cuda12.4-cudnn9-runtime"
      - "2.4.0-cuda12.4-cudnn9-devel"
      - "2.4.0-cuda12.1-cudnn9-runtime"
      - "2.4.0-cuda12.1-cudnn9-devel"
      - "2.4.0-cuda11.8-cudnn9-runtime"
      - "2.4.0-cuda11.8-cudnn9-devel"
      # PyTorch 2.3.x (for broader compatibility)
      - "2.3.1-cuda12.1-cudnn8-runtime"
      - "2.3.1-cuda12.1-cudnn8-devel"
      - "2.3.1-cuda11.8-cudnn8-runtime"
      - "2.3.1-cuda11.8-cudnn8-devel"
      - "2.3.0-cuda12.1-cudnn8-runtime"
      - "2.3.0-cuda12.1-cudnn8-devel"
      - "2.3.0-cuda11.8-cudnn8-runtime"
      - "2.3.0-cuda11.8-cudnn8-devel"
      # PyTorch 2.2.x
      - "2.2.2-cuda12.1-cudnn8-runtime"
      - "2.2.2-cuda12.1-cudnn8-devel"
      - "2.2.2-cuda11.8-cudnn8-runtime"
      - "2.2.2-cuda11.8-cudnn8-devel"
      # PyTorch 2.1.x (still widely used)
      - "2.1.2-cuda12.1-cudnn8-runtime"
      - "2.1.2-cuda12.1-cudnn8-devel"
      - "2.1.2-cuda11.8-cudnn8-runtime"
      - "2.1.2-cuda11.8-cudnn8-devel"
    discover:
      pattern: "^2\\.[3-6]\\.\\d+-cuda\\d+\\.\\d+-cudnn\\d+-(runtime|devel)$"
      limit: 30

  # Note: PyTorch official images don't have CPU-only variants.
  # The pytorch_cpu parser/builder is ready for future use with community images.

  # ==========================================================================
  # TensorFlow Official Images
  # ==========================================================================
  - id: tensorflow
    namespace: tensorflow
    repo: tensorflow
    parser: tensorflow_tf
    tags:
      # TensorFlow 2.18.x (latest)
      - "2.18.0"
      - "2.18.0-gpu"
      - "2.18.0-gpu-jupyter"
      # TensorFlow 2.17.x
      - "2.17.1"
      - "2.17.1-gpu"
      - "2.17.1-gpu-jupyter"
      - "2.17.0"
      - "2.17.0-gpu"
      - "2.17.0-gpu-jupyter"
      # TensorFlow 2.16.x
      - "2.16.2"
      - "2.16.2-gpu"
      - "2.16.2-gpu-jupyter"
      - "2.16.1"
      - "2.16.1-gpu"
      - "2.16.1-gpu-jupyter"
      # TensorFlow 2.15.x (LTS-like stability)
      - "2.15.1"
      - "2.15.1-gpu"
      - "2.15.1-gpu-jupyter"
      - "2.15.0"
      - "2.15.0-gpu"
      - "2.15.0-gpu-jupyter"
      # TensorFlow 2.14.x
      - "2.14.1"
      - "2.14.1-gpu"
      - "2.14.1-gpu-jupyter"

  # ==========================================================================
  # vLLM - High-throughput LLM Inference
  # ==========================================================================
  - id: vllm-openai
    namespace: vllm
    repo: vllm-openai
    parser: vllm_simple
    tags:
      - "latest"
      # v0.6.x series
      - "v0.6.6"
      - "v0.6.5"
      - "v0.6.4"
      - "v0.6.3"
      - "v0.6.2"
      - "v0.6.1"
      - "v0.6.0"
      # v0.5.x series (for compatibility)
      - "v0.5.5"
      - "v0.5.4"
      - "v0.5.3"
      - "v0.5.2"
      - "v0.5.1"
      - "v0.5.0"
      # v0.4.x series (older but still used)
      - "v0.4.3"
      - "v0.4.2"

  # ==========================================================================
  # Ollama - Local LLM Runner
  # ==========================================================================
  - id: ollama
    namespace: ollama
    repo: ollama
    parser: ollama_simple
    tags:
      - "latest"
      - "0.5.4"
      - "0.5.3"
      - "0.5.2"
      - "0.5.1"
      - "0.5.0"
      - "0.4.7"
      - "0.4.6"

  # ==========================================================================
  # NVIDIA CUDA Base Images
  # ==========================================================================
  - id: nvidia-cuda
    namespace: nvidia
    repo: cuda
    parser: nvidia_cuda
    tags:
      # CUDA 12.6 (latest)
      - "12.6.0-runtime-ubuntu24.04"
      - "12.6.0-devel-ubuntu24.04"
      - "12.6.0-cudnn9-runtime-ubuntu24.04"
      - "12.6.0-cudnn9-devel-ubuntu24.04"
      - "12.6.0-runtime-ubuntu22.04"
      - "12.6.0-devel-ubuntu22.04"
      - "12.6.0-cudnn9-runtime-ubuntu22.04"
      - "12.6.0-cudnn9-devel-ubuntu22.04"
      # CUDA 12.5
      - "12.5.1-runtime-ubuntu24.04"
      - "12.5.1-devel-ubuntu24.04"
      - "12.5.1-cudnn-runtime-ubuntu24.04"
      - "12.5.1-cudnn-devel-ubuntu24.04"
      - "12.5.1-runtime-ubuntu22.04"
      - "12.5.1-devel-ubuntu22.04"
      - "12.5.1-cudnn-runtime-ubuntu22.04"
      - "12.5.1-cudnn-devel-ubuntu22.04"
      # CUDA 12.4 (using 12.4.1 as latest patch)
      - "12.4.1-runtime-ubuntu22.04"
      - "12.4.1-devel-ubuntu22.04"
      - "12.4.1-cudnn-runtime-ubuntu22.04"
      - "12.4.1-cudnn-devel-ubuntu22.04"
      # CUDA 12.3
      - "12.3.2-runtime-ubuntu22.04"
      - "12.3.2-devel-ubuntu22.04"
      - "12.3.2-cudnn9-runtime-ubuntu22.04"
      - "12.3.2-cudnn9-devel-ubuntu22.04"
      # CUDA 12.2
      - "12.2.2-runtime-ubuntu22.04"
      - "12.2.2-devel-ubuntu22.04"
      - "12.2.2-cudnn8-runtime-ubuntu22.04"
      - "12.2.2-cudnn8-devel-ubuntu22.04"
      # CUDA 12.1
      - "12.1.1-runtime-ubuntu22.04"
      - "12.1.1-devel-ubuntu22.04"
      - "12.1.1-cudnn8-runtime-ubuntu22.04"
      - "12.1.1-cudnn8-devel-ubuntu22.04"
      # CUDA 11.8 (widely used for compatibility)
      - "11.8.0-runtime-ubuntu22.04"
      - "11.8.0-devel-ubuntu22.04"
      - "11.8.0-cudnn8-runtime-ubuntu22.04"
      - "11.8.0-cudnn8-devel-ubuntu22.04"
      - "11.8.0-runtime-ubuntu20.04"
      - "11.8.0-devel-ubuntu20.04"
      - "11.8.0-cudnn8-runtime-ubuntu20.04"
      - "11.8.0-cudnn8-devel-ubuntu20.04"
      # CUDA 11.7
      - "11.7.1-runtime-ubuntu22.04"
      - "11.7.1-devel-ubuntu22.04"
      - "11.7.1-cudnn8-runtime-ubuntu22.04"
      - "11.7.1-cudnn8-devel-ubuntu22.04"

ghcr:
  # ==========================================================================
  # Hugging Face Text Generation Inference (TGI)
  # ==========================================================================
  - id: tgi
    org: huggingface
    repo: text-generation-inference
    parser: tgi_simple
    tags:
      # TGI 3.x series (latest)
      # Note: 3.3.x tags not yet available; TGI parser supports CUDA-suffixed tags when they exist
      - "3.3.4"
      - "3.3.3"
      - "3.3.2"
      - "3.3.1"
      - "3.3.0"
      - "3.2.2"
      - "3.2.1"
      - "3.2.0"
      - "3.1.1"
      - "3.1.0"
      - "3.0.1"
      - "3.0.0"
      # TGI 2.x series (still widely used)
      - "2.4.1"
      - "2.4.0"
      - "2.3.1"
      - "2.3.0"
      - "2.2.0"
      - "2.1.0"
      - "2.0.4"
      - "2.0.3"
      - "2.0.2"
      - "2.0.1"
      - "2.0.0"
      # TGI 1.x series (legacy)
      - "1.4.5"
      - "1.4.4"
      - "1.4.0"

ngc:
  # ==========================================================================
  # NVIDIA NGC PyTorch
  # ==========================================================================
  - id: ngc-pytorch
    org: nvidia
    repo: pytorch
    parser: ngc_pytorch
    tags:
      # 2025 releases
      - "25.01-py3"
      # 2024 releases
      - "24.12-py3"
      - "24.11-py3"
      - "24.10-py3"
      - "24.09-py3"
      - "24.08-py3"
      - "24.07-py3"
      - "24.06-py3"
      - "24.05-py3"
      - "24.04-py3"
      - "24.03-py3"
      - "24.02-py3"
      - "24.01-py3"
      # 2023 releases (for older systems)
      - "23.12-py3"
      - "23.11-py3"
      - "23.10-py3"

  # ==========================================================================
  # NVIDIA NGC TensorFlow
  # ==========================================================================
  - id: ngc-tensorflow
    org: nvidia
    repo: tensorflow
    parser: ngc_tensorflow
    tags:
      # 2025 releases
      - "25.01-tf2-py3"
      # 2024 releases
      - "24.12-tf2-py3"
      - "24.11-tf2-py3"
      - "24.10-tf2-py3"
      - "24.09-tf2-py3"
      - "24.08-tf2-py3"
      - "24.07-tf2-py3"
      - "24.06-tf2-py3"
      - "24.05-tf2-py3"
      - "24.04-tf2-py3"
      - "24.03-tf2-py3"
      - "24.02-tf2-py3"
      - "24.01-tf2-py3"
      # 2023 releases
      - "23.12-tf2-py3"
      - "23.11-tf2-py3"
      - "23.10-tf2-py3"

  # ==========================================================================
  # NVIDIA Triton Inference Server
  # ==========================================================================
  - id: tritonserver
    org: nvidia
    repo: tritonserver
    parser: ngc_triton
    tags:
      # 2025 releases
      - "25.01-py3"
      - "25.11-py3"
      # 2024 releases
      - "24.12-py3"
      - "24.11-py3"
      - "24.10-py3"
      - "24.09-py3"
      - "24.08-py3"
      - "24.07-py3"
      - "24.06-py3"
      - "24.05-py3"
      - "24.04-py3"
      - "24.03-py3"
      - "24.02-py3"
      - "24.01-py3"
      # 2023 releases
      - "23.12-py3"

  # ==========================================================================
  # NVIDIA NGC JAX
  # ==========================================================================
  - id: ngc-jax
    org: nvidia
    repo: jax
    parser: ngc_jax
    tags:
      # 2025 releases
      - "25.01-py3"
      # 2024 releases
      - "24.12-py3"
      - "24.10-py3"
      - "24.08-py3"
      - "24.06-py3"
      - "24.04-py3"
      # 2023 releases
      - "23.12-py3"
      - "23.10-py3"

  # ==========================================================================
  # NVIDIA NeMo Framework (LLM Training)
  # ==========================================================================
  - id: ngc-nemo
    org: nvidia
    repo: nemo
    parser: ngc_nemo
    tags:
      # 2025 releases
      - "25.01"
      # 2024 releases
      - "24.12"
      - "24.11"
      - "24.09"
      - "24.07"
      - "24.05"
      - "24.03"
      - "24.01"
      # 2023 releases
      - "23.11"
      - "23.10"

  # ==========================================================================
  # NVIDIA RAPIDS (GPU-accelerated data science)
  # ==========================================================================
  - id: ngc-rapids
    org: nvidia
    team: rapidsai  # Used by NGC API for nested org structure
    repo: base
    parser: ngc_rapids
    tags:
      # 2024 releases
      - "24.10-cuda12.5-py3.12"
      - "24.08-cuda12.5-py3.11"
      - "24.06-cuda12.2-py3.11"
      - "24.04-cuda12.2-py3.10"
      - "24.02-cuda12.0-py3.10"
      # 2023 releases (for compatibility)
      - "23.12-cuda12.0-py3.10"
      - "23.10-cuda12.0-py3.10"

quay:
  # ==========================================================================
  # Jupyter Docker Stacks (quay.io)
  # Official notebook environments maintained by Project Jupyter
  # ==========================================================================
  - id: jupyter-datascience
    org: jupyter
    repo: datascience-notebook
    parser: jupyter_stack
    tags:
      - "latest"
      - "python-3.13"
      - "python-3.12"
      - "python-3.11"

  - id: jupyter-scipy
    org: jupyter
    repo: scipy-notebook
    parser: jupyter_stack
    tags:
      - "latest"
      - "python-3.13"
      - "python-3.12"
      - "python-3.11"

  - id: jupyter-tensorflow
    org: jupyter
    repo: tensorflow-notebook
    parser: jupyter_stack
    tags:
      - "latest"
      - "python-3.12"
      - "python-3.11"

  - id: jupyter-pytorch
    org: jupyter
    repo: pytorch-notebook
    parser: jupyter_stack
    tags:
      - "latest"
      - "python-3.12"
      - "python-3.11"

  - id: jupyter-minimal
    org: jupyter
    repo: minimal-notebook
    parser: jupyter_stack
    tags:
      - "latest"
      - "python-3.13"
      - "python-3.12"

  - id: jupyter-base
    org: jupyter
    repo: base-notebook
    parser: jupyter_stack
    tags:
      - "latest"
      - "python-3.13"
      - "python-3.12"

  - id: jupyter-pyspark
    org: jupyter
    repo: pyspark-notebook
    parser: jupyter_stack
    tags:
      - "latest"
      - "python-3.12"
      - "python-3.11"

  - id: jupyter-all-spark
    org: jupyter
    repo: all-spark-notebook
    parser: jupyter_stack
    tags:
      - "latest"
      - "python-3.12"

aws:
  # ==========================================================================
  # AWS Deep Learning Containers - PyTorch Training
  # Hosted at public.ecr.aws/deep-learning-containers/
  # Note: Only tags available in ECR Public Gallery are listed here.
  # Tags found via https://gallery.ecr.aws/deep-learning-containers/
  # ==========================================================================
  - id: aws-pytorch-training
    repo: pytorch-training
    parser: aws_dlc
    tags:
      # PyTorch 2.5.x - available in ECR Public
      - "2.5.1-gpu-py311-cu124-ubuntu22.04-ec2"
      - "2.5.1-cpu-py311-ubuntu22.04-ec2"

  - id: aws-pytorch-inference
    repo: pytorch-inference
    parser: aws_dlc
    tags:
      # PyTorch 2.5.x
      - "2.5.1-gpu-py311-cu124-ubuntu22.04-ec2"
      - "2.5.1-cpu-py311-ubuntu22.04-ec2"

  # Note: TensorFlow DLCs are not available in ECR Public Gallery.
  # They are only accessible from the private AWS account (763104351884).

gcp:
  # ==========================================================================
  # GCP Deep Learning Containers
  # Hosted at gcr.io/deeplearning-platform-release/
  # Available repos discovered via gcr.io API - 368 total repos available
  # ==========================================================================

  # PyTorch GPU (recent versions)
  - id: gcp-pytorch-gpu
    repo: pytorch-gpu.2-4
    parser: gcp_dlc
    tags:
      - "latest"

  - id: gcp-pytorch-gpu-2-3
    repo: pytorch-gpu.2-3
    parser: gcp_dlc
    tags:
      - "latest"

  - id: gcp-pytorch-gpu-2-2
    repo: pytorch-gpu.2-2
    parser: gcp_dlc
    tags:
      - "latest"

  - id: gcp-pytorch-gpu-2-1
    repo: pytorch-gpu.2-1
    parser: gcp_dlc
    tags:
      - "latest"

  - id: gcp-pytorch-gpu-2-0
    repo: pytorch-gpu.2-0
    parser: gcp_dlc
    tags:
      - "latest"

  # TensorFlow GPU (recent versions)
  - id: gcp-tensorflow-gpu
    repo: tf-gpu.2-17
    parser: gcp_dlc
    tags:
      - "latest"

  - id: gcp-tensorflow-gpu-2-16
    repo: tf-gpu.2-16
    parser: gcp_dlc
    tags:
      - "latest"

  - id: gcp-tensorflow-gpu-2-15
    repo: tf-gpu.2-15
    parser: gcp_dlc
    tags:
      - "latest"

  # TensorFlow CPU
  - id: gcp-tensorflow-cpu
    repo: tf-cpu.2-17
    parser: gcp_dlc
    tags:
      - "latest"

  # Base CUDA images (for custom builds)
  - id: gcp-base-cuda
    repo: base-cu121
    parser: gcp_dlc
    tags:
      - "latest"

  - id: gcp-base-cuda-122
    repo: base-cu122
    parser: gcp_dlc
    tags:
      - "latest"

  - id: gcp-base-cuda-123
    repo: base-cu123
    parser: gcp_dlc
    tags:
      - "latest"

  - id: gcp-base-cuda-124
    repo: base-cu124
    parser: gcp_dlc
    tags:
      - "latest"
